{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the Models Used in the Binary Classification Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Overview and Setup\n",
    "\n",
    "This is an example of how someone might generate and store models that can be compared for fairness. \n",
    "\n",
    "## Notebook Contents\n",
    "\n",
    "[Part 1](#part1) - Data and Analysis\n",
    "\n",
    "[Part 2](#part2) - Length of Stay Models (Baseline)\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[Part 2.1](#part2.1) - From-The-Box Models\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[Part 2.2](#part2.2) - AIF360 Fairness-Aware  (In-Process) Models\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[Part 2.3](#part2.3) - FairLearn Fairness-Aware  (In-Process) Models\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[Part 2.4](#part2.4) - Other Methods\n",
    "\n",
    "[Part 3](#part3) - Comparing Models\n",
    "    Includes the fairMLHealth model comparison tool, as well as an example of the FairLearn Dashboard.\n",
    "\n",
    "[Part 4](#part4) - Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from fairMLHealth.utils import helpers, model_comparison\n",
    "from fairlearn.metrics import demographic_parity_difference, demographic_parity_ratio, equalized_odds_difference, equalized_odds_ratio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0:00:00.000028 (hr:mn:sc)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "def check_timer(start_time=None):\n",
    "    if start_time is not None:\n",
    "        elapsed_time = datetime.datetime.now() - start_time\n",
    "        rprt = f\"{elapsed_time} (hr:mn:sc)\"\n",
    "        return rprt\n",
    "        return elapsed_time\n",
    "    else:\n",
    "        return datetime.datetime.now()\n",
    "\n",
    "start_time = check_timer()\n",
    "check_timer(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "#warnings.filterwarnings('ignore', module='numpy' )\n",
    "warnings.filterwarnings('ignore', module='tensorflow' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "----\n",
    "# Part 1 - Data and Analysis <a class=\"anchor\" id=\"part1\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading MIMIC III Data\n",
    "\n",
    "This example uses a data subset from the [MIMIC-III clinical database](https://mimic.physionet.org/gettingstarted/access/) to predict \"length of stay\" (LOS) value. For this example, LOS is total ICU time for a given hospital admission in patients 65 and above. The raw LOS value is then converted to a binary value specifying whether an admission's length of stay is greater than the sample mean. A baseline model is then generated using the Scikit-Learn RandomForestClassifier.\n",
    "\n",
    "Note that the code below will automatically unzip and format all necessary data for these experiments from a raw download of MIMIC-III data (saving the formatted data in the same MIMIC folder). MIMIC-III is a freely available database, however all users must pass a quick human subjects certification course. If you would like to run this example on your own, [follow these steps to be granted access to MIMIC III](https://mimic.physionet.org/gettingstarted/access/) and download the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# path_to_mimic_data_folder = \"[path to your downloaded data folder]\"\n",
    "path_to_mimic_data_folder = \"~/data/MIMIC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output file for combined data and models\n",
    "output_file = os.path.expanduser(\"~/data/fairness_and_bias/mimic_model_comparison/binary_classification.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data Subset <a id=\"datasubset\"></a>\n",
    "Example models in this notebook use data from all years of the MIMIC-III dataset for patients aged 65 and older. Data are imported at the encounter level with all additional patient identification dropped. All models include an \"AGE\" feature, simplified to 5-year bins, as well as boolean diagnosis and procedure features categorized through the Clinical Classifications Software system ([HCUP](https://www.hcup-us.ahrq.gov/toolssoftware/ccs/ccs.jsp)). All features other than age are one-hot encoded and prefixed with their variable type (e.g. \"GENDER_\", \"ETHNICITY_\").  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " This data subset has 22434 total observations and 648 input features \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw Feature</th>\n",
       "      <th>Category Count (Encoded Features)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DIAGNOSIS</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ETHNICITY</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GENDER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INSURANCE</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LANGUAGE</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MARRIED</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PROCEDURE</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RELIGION</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Raw Feature  Category Count (Encoded Features)\n",
       "0         AGE                                  1\n",
       "1   DIAGNOSIS                                282\n",
       "2   ETHNICITY                                 41\n",
       "3      GENDER                                  1\n",
       "4   INSURANCE                                  5\n",
       "5    LANGUAGE                                 69\n",
       "6     MARRIED                                  7\n",
       "7   PROCEDURE                                222\n",
       "8    RELIGION                                 20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADMIT_ID</th>\n",
       "      <th>AGE</th>\n",
       "      <th>GENDER_M</th>\n",
       "      <th>ETHNICITY_AMERICAN INDIAN/ALASKA NATIVE</th>\n",
       "      <th>ETHNICITY_AMERICAN INDIAN/ALASKA NATIVE FEDERALLY RECOGNIZED TRIBE</th>\n",
       "      <th>ETHNICITY_ASIAN</th>\n",
       "      <th>ETHNICITY_ASIAN - ASIAN INDIAN</th>\n",
       "      <th>ETHNICITY_ASIAN - CAMBODIAN</th>\n",
       "      <th>ETHNICITY_ASIAN - CHINESE</th>\n",
       "      <th>ETHNICITY_ASIAN - FILIPINO</th>\n",
       "      <th>...</th>\n",
       "      <th>PROCEDURE_CCS_222</th>\n",
       "      <th>PROCEDURE_CCS_223</th>\n",
       "      <th>PROCEDURE_CCS_224</th>\n",
       "      <th>PROCEDURE_CCS_225</th>\n",
       "      <th>PROCEDURE_CCS_226</th>\n",
       "      <th>PROCEDURE_CCS_227</th>\n",
       "      <th>PROCEDURE_CCS_228</th>\n",
       "      <th>PROCEDURE_CCS_229</th>\n",
       "      <th>PROCEDURE_CCS_231</th>\n",
       "      <th>length_of_stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>843270</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.144444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>830178</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.496528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>802276</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.768056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>875616</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.988889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>840524</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.364583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 650 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ADMIT_ID   AGE  GENDER_M  ETHNICITY_AMERICAN INDIAN/ALASKA NATIVE  \\\n",
       "0    843270  65.0         0                                        0   \n",
       "1    830178  70.0         1                                        0   \n",
       "2    802276  75.0         1                                        0   \n",
       "5    875616  70.0         1                                        0   \n",
       "7    840524  75.0         1                                        0   \n",
       "\n",
       "   ETHNICITY_AMERICAN INDIAN/ALASKA NATIVE FEDERALLY RECOGNIZED TRIBE  \\\n",
       "0                                                  0                    \n",
       "1                                                  0                    \n",
       "2                                                  0                    \n",
       "5                                                  0                    \n",
       "7                                                  0                    \n",
       "\n",
       "   ETHNICITY_ASIAN  ETHNICITY_ASIAN - ASIAN INDIAN  \\\n",
       "0                0                               0   \n",
       "1                0                               0   \n",
       "2                0                               0   \n",
       "5                0                               0   \n",
       "7                0                               0   \n",
       "\n",
       "   ETHNICITY_ASIAN - CAMBODIAN  ETHNICITY_ASIAN - CHINESE  \\\n",
       "0                            0                          0   \n",
       "1                            0                          0   \n",
       "2                            0                          0   \n",
       "5                            0                          0   \n",
       "7                            0                          0   \n",
       "\n",
       "   ETHNICITY_ASIAN - FILIPINO  ...  PROCEDURE_CCS_222  PROCEDURE_CCS_223  \\\n",
       "0                           0  ...                  0                  0   \n",
       "1                           0  ...                  1                  0   \n",
       "2                           0  ...                  0                  0   \n",
       "5                           0  ...                  0                  0   \n",
       "7                           0  ...                  1                  0   \n",
       "\n",
       "   PROCEDURE_CCS_224  PROCEDURE_CCS_225  PROCEDURE_CCS_226  PROCEDURE_CCS_227  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  0                  0                  0                  0   \n",
       "5                  0                  0                  0                  1   \n",
       "7                  0                  0                  0                  1   \n",
       "\n",
       "   PROCEDURE_CCS_228  PROCEDURE_CCS_229  PROCEDURE_CCS_231  length_of_stay  \n",
       "0                  0                  0                  0        1.144444  \n",
       "1                  0                  0                  0        5.496528  \n",
       "2                  0                  0                  0        6.768056  \n",
       "5                  0                  0                  0        6.988889  \n",
       "7                  0                  0                  0        5.364583  \n",
       "\n",
       "[5 rows x 650 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = helpers.load_mimic3_example(path_to_mimic_data_folder) \n",
    "df.drop('GENDER_F', axis=1, inplace=True)\n",
    "df = df.loc[df['AGE'].ge(65),:]\n",
    "helpers.print_feature_table(df)\n",
    "display(Markdown('---'))\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_6c53c366_f8a9_11ea_80ea_f0189849bf4brow0_col1,#T_6c53c366_f8a9_11ea_80ea_f0189849bf4brow1_col1{\n",
       "            background-color:  aquamarine;\n",
       "        }</style><table id=\"T_6c53c366_f8a9_11ea_80ea_f0189849bf4b\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >count</th>        <th class=\"col_heading level0 col1\" >mean</th>        <th class=\"col_heading level0 col2\" >std</th>        <th class=\"col_heading level0 col3\" >min</th>        <th class=\"col_heading level0 col4\" >25%</th>        <th class=\"col_heading level0 col5\" >50%</th>        <th class=\"col_heading level0 col6\" >75%</th>        <th class=\"col_heading level0 col7\" >max</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_6c53c366_f8a9_11ea_80ea_f0189849bf4blevel0_row0\" class=\"row_heading level0 row0\" >length_of_stay</th>\n",
       "                        <td id=\"T_6c53c366_f8a9_11ea_80ea_f0189849bf4brow0_col0\" class=\"data row0 col0\" >22434.000000</td>\n",
       "                        <td id=\"T_6c53c366_f8a9_11ea_80ea_f0189849bf4brow0_col1\" class=\"data row0 col1\" >9.115200</td>\n",
       "                        <td id=\"T_6c53c366_f8a9_11ea_80ea_f0189849bf4brow0_col2\" class=\"data row0 col2\" >6.208700</td>\n",
       "                        <td id=\"T_6c53c366_f8a9_11ea_80ea_f0189849bf4brow0_col3\" class=\"data row0 col3\" >0.004200</td>\n",
       "                        <td id=\"T_6c53c366_f8a9_11ea_80ea_f0189849bf4brow0_col4\" class=\"data row0 col4\" >4.735200</td>\n",
       "                        <td id=\"T_6c53c366_f8a9_11ea_80ea_f0189849bf4brow0_col5\" class=\"data row0 col5\" >7.579900</td>\n",
       "                        <td id=\"T_6c53c366_f8a9_11ea_80ea_f0189849bf4brow0_col6\" class=\"data row0 col6\" >12.017700</td>\n",
       "                        <td id=\"T_6c53c366_f8a9_11ea_80ea_f0189849bf4brow0_col7\" class=\"data row0 col7\" >29.988900</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6c53c366_f8a9_11ea_80ea_f0189849bf4blevel0_row1\" class=\"row_heading level0 row1\" >long_los</th>\n",
       "                        <td id=\"T_6c53c366_f8a9_11ea_80ea_f0189849bf4brow1_col0\" class=\"data row1 col0\" >22434.000000</td>\n",
       "                        <td id=\"T_6c53c366_f8a9_11ea_80ea_f0189849bf4brow1_col1\" class=\"data row1 col1\" >0.388000</td>\n",
       "                        <td id=\"T_6c53c366_f8a9_11ea_80ea_f0189849bf4brow1_col2\" class=\"data row1 col2\" >0.487300</td>\n",
       "                        <td id=\"T_6c53c366_f8a9_11ea_80ea_f0189849bf4brow1_col3\" class=\"data row1 col3\" >0.000000</td>\n",
       "                        <td id=\"T_6c53c366_f8a9_11ea_80ea_f0189849bf4brow1_col4\" class=\"data row1 col4\" >0.000000</td>\n",
       "                        <td id=\"T_6c53c366_f8a9_11ea_80ea_f0189849bf4brow1_col5\" class=\"data row1 col5\" >0.000000</td>\n",
       "                        <td id=\"T_6c53c366_f8a9_11ea_80ea_f0189849bf4brow1_col6\" class=\"data row1 col6\" >1.000000</td>\n",
       "                        <td id=\"T_6c53c366_f8a9_11ea_80ea_f0189849bf4brow1_col7\" class=\"data row1 col7\" >1.000000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa2b3719890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate a binary target flagging whether an observation's length_of_stay value is above or below the mean. \n",
    "mean_val=df['length_of_stay'].mean()\n",
    "df['long_los'] = df['length_of_stay'].apply(lambda x: 1 if x > mean_val else 0)\n",
    "los_tbl = df[['length_of_stay', 'long_los']].describe().transpose().round(4)\n",
    "display(los_tbl.style.applymap(helpers.highlight_col, subset=pd.IndexSlice[:, 'mean']))\n",
    "\n",
    "# Display LOS distributions\n",
    "display(Markdown('---'))\n",
    "ax = df['length_of_stay'].plot(kind='kde', title=\"Probability Density of Length of Stay\")\n",
    "ax.set_xlabel(\"Length of Stay in Days\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "----\n",
    "# Part 2 - Length of Stay Models <a class=\"anchor\" id=\"part2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as sk_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline - Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Prediction Scores for Random Sampling: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  LOS > mean       0.61      0.62      0.62     13730\n",
      " LOS <= mean       0.39      0.39      0.39      8704\n",
      "\n",
      "    accuracy                           0.53     22434\n",
      "   macro avg       0.50      0.50      0.50     22434\n",
      "weighted avg       0.53      0.53      0.53     22434\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# generate \"predictions\" as random sample of target values\n",
    "y_test = df['long_los']\n",
    "pos_weight = y_test.mean()\n",
    "weights = [1-pos_weight, pos_weight]\n",
    "values = list(set(y_test))\n",
    "y_pred_baseline = np.array(random.choices(values, weights, k=df.shape[0]))\n",
    "y_prob_baseline = y_pred_baseline\n",
    "\n",
    "# display baseline performance \n",
    "print(\"\\n\", \"Prediction Scores for Random Sampling:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_baseline, target_names=['LOS > mean', 'LOS <= mean']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data for other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset and Split Data\n",
    "X = df.loc[:,[c for c in df.columns if c not in ['ADMIT_ID','length_of_stay', 'long_los']]]\n",
    "y = df.loc[:, ['long_los']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.33, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Part 2.1 - From-The-Box Models <a class=\"anchor\" id=\"part2.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 0:00:00.196712 (hr:mn:sc)\n",
      "\n",
      " Naive Bayes Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " LOS <= mean       0.76      0.85      0.80      4531\n",
      "  LOS > mean       0.71      0.58      0.64      2873\n",
      "\n",
      "    accuracy                           0.75      7404\n",
      "   macro avg       0.74      0.72      0.72      7404\n",
      "weighted avg       0.74      0.75      0.74      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Set model parameters (currently set as default values, but defined here to be explicit)\n",
    "nb_params = {'alpha':20, 'fit_prior':True}\n",
    "\n",
    "# Train Model\n",
    "start_time = check_timer()\n",
    "nb_model = BernoulliNB(**nb_params)\n",
    "nb_model.fit(X_train, y_train.iloc[:,0])\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "print(\"Model finished in\", check_timer(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Naive Bayes Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_nb, target_names=['LOS <= mean', 'LOS > mean']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 0:00:00.533237 (hr:mn:sc)\n",
      "\n",
      " Decision Tree Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " LOS <= mean       0.74      0.85      0.79      4531\n",
      "  LOS > mean       0.69      0.52      0.59      2873\n",
      "\n",
      "    accuracy                           0.72      7404\n",
      "   macro avg       0.71      0.69      0.69      7404\n",
      "weighted avg       0.72      0.72      0.71      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set model parameters (currently set as default values, but defined here to be explicit)\n",
    "dt_params = {'min_samples_split': 10,\n",
    " 'min_samples_leaf': 2,\n",
    " 'max_depth': 10,\n",
    " 'criterion': 'entropy'}\n",
    "\n",
    "# Train Model\n",
    "start_time = check_timer()\n",
    "dt_model = DecisionTreeClassifier(**dt_params)\n",
    "dt_model.fit(X_train, y_train.iloc[:,0])\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "print(\"Model finished in\", check_timer(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Decision Tree Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_dt, target_names=['LOS <= mean', 'LOS > mean']) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 0:02:38.296874 (hr:mn:sc)\n",
      "\n",
      " Random Forest Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " LOS <= mean       0.77      0.90      0.83      4531\n",
      "  LOS > mean       0.78      0.57      0.66      2873\n",
      "\n",
      "    accuracy                           0.77      7404\n",
      "   macro avg       0.77      0.74      0.74      7404\n",
      "weighted avg       0.77      0.77      0.76      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set model parameters (currently set as default values, but defined here to be explicit)\n",
    "rf_params = {'criterion':'entropy', 'n_estimators': 1800, 'min_samples_split': 5, 'bootstrap': False}\n",
    "\n",
    "# Train Model\n",
    "start_time = check_timer()\n",
    "rf_model = RandomForestClassifier(**rf_params)\n",
    "rf_model.fit(X_train, y_train.iloc[:,0])\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(\"Model finished in\", check_timer(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Random Forest Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_rf, target_names=['LOS <= mean', 'LOS > mean']) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logit Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 0:00:09.587844 (hr:mn:sc)\n",
      "\n",
      " Logit Regression Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " LOS <= mean       0.79      0.88      0.83      4531\n",
      "  LOS > mean       0.76      0.63      0.69      2873\n",
      "\n",
      "    accuracy                           0.78      7404\n",
      "   macro avg       0.77      0.75      0.76      7404\n",
      "weighted avg       0.78      0.78      0.77      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_params = {'penalty':\"none\", 'max_iter':10**4}\n",
    "\n",
    "# Train Model\n",
    "start_time = check_timer()\n",
    "lr_model = LogisticRegression(**lr_params)\n",
    "lr_model.fit(X_train, y_train.iloc[:,0])\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "print(\"Model finished in\", check_timer(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Logit Regression Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_lr, zero_division=0, target_names=['LOS <= mean', 'LOS > mean']) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 0:00:23.015004 (hr:mn:sc)\n",
      "\n",
      " SVM Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " LOS <= mean       0.75      0.94      0.83      4531\n",
      "  LOS > mean       0.83      0.51      0.63      2873\n",
      "\n",
      "    accuracy                           0.77      7404\n",
      "   macro avg       0.79      0.72      0.73      7404\n",
      "weighted avg       0.78      0.77      0.75      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', message=\"Liblinear failed to converge, increase the number of iterations.\")\n",
    "\n",
    "svm_params = {'max_iter':10**4}\n",
    "\n",
    "# Train Model\n",
    "start_time = check_timer()\n",
    "svm_model = LinearSVC(**svm_params)\n",
    "svm_model.fit(X_train, y_train.iloc[:,0])\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "print(\"Model finished in\", check_timer(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"SVM Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_svm, target_names=['LOS <= mean', 'LOS > mean'], zero_division=0) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 0:00:00.522620 (hr:mn:sc)\n",
      "\n",
      " Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " LOS <= mean       0.73      0.91      0.81      4531\n",
      "  LOS > mean       0.76      0.47      0.58      2873\n",
      "\n",
      "    accuracy                           0.74      7404\n",
      "   macro avg       0.74      0.69      0.69      7404\n",
      "weighted avg       0.74      0.74      0.72      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "lgb_params = {'objective':'binary', 'metric':'auc', 'learning_rate':0.03,\n",
    "              'num_leaves':10, 'max_depth':3}\n",
    "\n",
    "start_time = check_timer()\n",
    "lgb_model = lgb.LGBMClassifier(**lgb_params)\n",
    "lgb_model.fit(X_train, y_train.iloc[:,0])\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "print(\"Model finished in\", check_timer(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_lgb, target_names=['LOS <= mean', 'LOS > mean']) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 0:02:05.872574 (hr:mn:sc)\n",
      "\n",
      " Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " LOS <= mean       0.79      0.88      0.83      4531\n",
      "  LOS > mean       0.77      0.63      0.70      2873\n",
      "\n",
      "    accuracy                           0.78      7404\n",
      "   macro avg       0.78      0.76      0.76      7404\n",
      "weighted avg       0.78      0.78      0.78      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Set model parameters\n",
    "xgb_params = {'colsample_bytree': 1.0, 'gamma': 2, 'learning_rate': 0.05, 'max_depth': 5, \n",
    "                'min_child_weight': 1,  'n_estimators': 600, 'subsample': 0.6}\n",
    "\n",
    "# Train Model\n",
    "xgb_model = XGBClassifier(**xgb_params)\n",
    "start_time = check_timer()\n",
    "xgb_model.fit(X_train, y_train.iloc[:,0])\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "print(\"Model finished in\", check_timer(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_xgb, target_names=['LOS <= mean', 'LOS > mean']) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Part 2.2 - AIF360 Fairness-Aware  (In-Process) Models <a class=\"anchor\" id=\"part2.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>GENDER_M</th>\n",
       "      <th>ETHNICITY_AMERICAN INDIAN/ALASKA NATIVE</th>\n",
       "      <th>ETHNICITY_AMERICAN INDIAN/ALASKA NATIVE FEDERALLY RECOGNIZED TRIBE</th>\n",
       "      <th>ETHNICITY_ASIAN</th>\n",
       "      <th>ETHNICITY_ASIAN - ASIAN INDIAN</th>\n",
       "      <th>ETHNICITY_ASIAN - CAMBODIAN</th>\n",
       "      <th>ETHNICITY_ASIAN - CHINESE</th>\n",
       "      <th>ETHNICITY_ASIAN - FILIPINO</th>\n",
       "      <th>ETHNICITY_ASIAN - JAPANESE</th>\n",
       "      <th>...</th>\n",
       "      <th>PROCEDURE_CCS_222</th>\n",
       "      <th>PROCEDURE_CCS_223</th>\n",
       "      <th>PROCEDURE_CCS_224</th>\n",
       "      <th>PROCEDURE_CCS_225</th>\n",
       "      <th>PROCEDURE_CCS_226</th>\n",
       "      <th>PROCEDURE_CCS_227</th>\n",
       "      <th>PROCEDURE_CCS_228</th>\n",
       "      <th>PROCEDURE_CCS_229</th>\n",
       "      <th>PROCEDURE_CCS_231</th>\n",
       "      <th>long_los</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 649 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AGE  GENDER_M  ETHNICITY_AMERICAN INDIAN/ALASKA NATIVE  \\\n",
       "0  80.0         1                                        0   \n",
       "1  80.0         1                                        0   \n",
       "2  80.0         0                                        0   \n",
       "3  65.0         0                                        0   \n",
       "4  75.0         1                                        0   \n",
       "\n",
       "   ETHNICITY_AMERICAN INDIAN/ALASKA NATIVE FEDERALLY RECOGNIZED TRIBE  \\\n",
       "0                                                  0                    \n",
       "1                                                  0                    \n",
       "2                                                  0                    \n",
       "3                                                  0                    \n",
       "4                                                  0                    \n",
       "\n",
       "   ETHNICITY_ASIAN  ETHNICITY_ASIAN - ASIAN INDIAN  \\\n",
       "0                0                               0   \n",
       "1                0                               0   \n",
       "2                0                               0   \n",
       "3                0                               0   \n",
       "4                0                               0   \n",
       "\n",
       "   ETHNICITY_ASIAN - CAMBODIAN  ETHNICITY_ASIAN - CHINESE  \\\n",
       "0                            0                          0   \n",
       "1                            0                          0   \n",
       "2                            0                          0   \n",
       "3                            0                          0   \n",
       "4                            0                          0   \n",
       "\n",
       "   ETHNICITY_ASIAN - FILIPINO  ETHNICITY_ASIAN - JAPANESE  ...  \\\n",
       "0                           0                           0  ...   \n",
       "1                           0                           0  ...   \n",
       "2                           0                           0  ...   \n",
       "3                           0                           0  ...   \n",
       "4                           0                           0  ...   \n",
       "\n",
       "   PROCEDURE_CCS_222  PROCEDURE_CCS_223  PROCEDURE_CCS_224  PROCEDURE_CCS_225  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  1                  0                  0                  0   \n",
       "3                  0                  0                  0                  0   \n",
       "4                  0                  0                  0                  0   \n",
       "\n",
       "   PROCEDURE_CCS_226  PROCEDURE_CCS_227  PROCEDURE_CCS_228  PROCEDURE_CCS_229  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  0                  0                  0                  0   \n",
       "3                  0                  0                  0                  0   \n",
       "4                  0                  0                  0                  0   \n",
       "\n",
       "   PROCEDURE_CCS_231  long_los  \n",
       "0                  0         0  \n",
       "1                  0         0  \n",
       "2                  0         1  \n",
       "3                  1         0  \n",
       "4                  0         1  \n",
       "\n",
       "[5 rows x 649 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "df = pd.concat([test_data, train_data], ignore_index=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aif360.datasets as aifdata\n",
    "\n",
    "aif_data = pd.concat([X, y], axis=1)\n",
    "los_dataset = aifdata.StandardDataset(df=aif_data, \n",
    "                        label_name='long_los',\n",
    "                        favorable_classes=[1],\n",
    "                        instance_weights_name=None,\n",
    "                        categorical_features=['AGE'],\n",
    "                        protected_attribute_names=['LANGUAGE_ENGL'],       \n",
    "                        privileged_classes=[[1]],                   \n",
    "                        custom_preprocessing=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christineallen/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/christineallen/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/christineallen/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/christineallen/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/christineallen/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/christineallen/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "def test_thresholds(dataset, model, thresh_arr=np.linspace(0.01, 0.5, 50)):\n",
    "    ''' from AIF360 tutorial, used throughout the tutorial to find best \n",
    "            threshold using a validation set\n",
    "    '''\n",
    "    try:\n",
    "        # sklearn classifier\n",
    "        y_val_pred_prob = model.predict_proba(dataset.features)\n",
    "        pos_ind = np.where(model.classes_ == dataset.favorable_label)[0][0]\n",
    "    except AttributeError:\n",
    "        # aif360 inprocessing algorithm\n",
    "        y_val_pred_prob = model.predict(dataset).scores\n",
    "        pos_ind = 0\n",
    "    \n",
    "    #\n",
    "    sens_ind = 0\n",
    "    sens_attr = dataset.protected_attribute_names[sens_ind]\n",
    "    unprivileged_groups = [{sens_attr: v} for v in\n",
    "                       dataset.unprivileged_protected_attributes[sens_ind]]\n",
    "    privileged_groups = [{sens_attr: v} for v in\n",
    "                     dataset.privileged_protected_attributes[sens_ind]]\n",
    "    #\n",
    "    metric_arrs = defaultdict(list)\n",
    "    for thresh in thresh_arr:\n",
    "        y_val_pred = (y_val_pred_prob[:, pos_ind] > thresh).astype(np.float64)\n",
    "\n",
    "        dataset_pred = dataset.copy()\n",
    "        dataset_pred.labels = y_val_pred\n",
    "        metric = ClassificationMetric(\n",
    "                dataset, dataset_pred,\n",
    "                unprivileged_groups=unprivileged_groups,\n",
    "                privileged_groups=privileged_groups)\n",
    "\n",
    "        metric_arrs['bal_acc'].append((metric.true_positive_rate()\n",
    "                                     + metric.true_negative_rate()) / 2)\n",
    "        metric_arrs['avg_odds_diff'].append(metric.average_odds_difference())\n",
    "        metric_arrs['disp_imp'].append(metric.disparate_impact())\n",
    "        metric_arrs['stat_par_diff'].append(metric.statistical_parity_difference())\n",
    "        metric_arrs['eq_opp_diff'].append(metric.equal_opportunity_difference())\n",
    "        metric_arrs['theil_ind'].append(metric.theil_index())\n",
    "    \n",
    "    return metric_arrs\n",
    "\n",
    "\n",
    "def aif_dataset_measures(dataset, models):\n",
    "    ''' alterned version of test_thresholds from AIF360 tutorial\n",
    "    '''\n",
    "    if not isinstance(models, (list, dict)):\n",
    "        models = [models]\n",
    "    if not isinstance(models, dict):\n",
    "        models = {f'model_{i}':m for i,m in enumerate(models)}\n",
    "    \n",
    "    #\n",
    "    sens_ind = 0\n",
    "    sens_attr = dataset.protected_attribute_names[sens_ind]\n",
    "    unprivileged_groups = [{sens_attr: v} for v in\n",
    "                       dataset.unprivileged_protected_attributes[sens_ind]]\n",
    "    privileged_groups = [{sens_attr: v} for v in\n",
    "                     dataset.privileged_protected_attributes[sens_ind]]\n",
    "    #\n",
    "    metric_dict = defaultdict(list)\n",
    "    for name,model in models.items():\n",
    "        y_pred = model.predict(dataset).labels\n",
    "        dataset_pred = dataset.copy()\n",
    "        dataset_pred.labels = y_pred\n",
    "        metric = ClassificationMetric(\n",
    "                    dataset, dataset_pred,\n",
    "                    unprivileged_groups=unprivileged_groups,\n",
    "                    privileged_groups=privileged_groups)\n",
    "        \n",
    "        metric_dict['Disparate Impact Ratio'].append(metric.disparate_impact())\n",
    "        metric_dict['Statistical Parity Difference'].append(metric.statistical_parity_difference())\n",
    "        metric_dict['Average Odds Difference'].append(metric.average_odds_difference())\n",
    "        metric_dict['Equal Opportunity Difference'].append(metric.equal_opportunity_difference())\n",
    "        metric_dict['Balanced Accuracy Difference'].append((metric.true_positive_rate()\n",
    "                                     + metric.true_negative_rate()) / 2)\n",
    "        metric_dict['Between-Group Coefficient of Variation'].append(metric.between_group_coefficient_of_variation())\n",
    "        metric_dict['Theil Index'].append(metric.theil_index())\n",
    "    \n",
    "    results = pd.DataFrame().from_dict(metric_dict).transpose()\n",
    "    results.columns = models.keys()\n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GerryFair Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1, error: 0.20986003387715074, fairness violation: 0.0036408985147281703, violated group size: 0.1964428991709013\n",
      "iteration: 2, error: 0.20986003387715074, fairness violation: 0.0036408985147281703, violated group size: 0.1964428991709013\n",
      "iteration: 3, error: 0.20986003387715074, fairness violation: 0.0036408985147281703, violated group size: 0.1964428991709013\n",
      "iteration: 4, error: 0.20986003387715074, fairness violation: 0.0036408985147281703, violated group size: 0.1964428991709013\n",
      "iteration: 5, error: 0.20986003387715074, fairness violation: 0.0036408985147281703, violated group size: 0.1964428991709013\n",
      "Model finished in 0:00:12.300074 (hr:mn:sc)\n",
      "\n",
      " Note: Theoretically a predictor can be set, but no valid argument could be found during testing. Per the documentation: \"predictor: Hypothesis class for the Learner. Supports LR, SVM, KR, Trees\"\n"
     ]
    }
   ],
   "source": [
    "from aif360.algorithms.inprocessing import GerryFairClassifier\n",
    "\n",
    "C = 100\n",
    "print_flag = True\n",
    "gamma = .005\n",
    "\n",
    "\n",
    "aif_gf_model = GerryFairClassifier(fairness_def='FN', #fairness_def: Fairness notion, FP, FN\n",
    "                                   C=C, \n",
    "                                   printflag=print_flag, \n",
    "                                   gamma=gamma, \n",
    "                                   max_iters=500, \n",
    "                                   heatmapflag=False)\n",
    "\n",
    "start_time = check_timer()\n",
    "aif_gf_model.fit(los_dataset, early_termination=True)\n",
    "yhat_aifgf = aif_gf_model.predict(los_dataset, threshold=False)\n",
    "print(\"Model finished in\", check_timer(start_time))\n",
    "\n",
    "print(\"\\n\",\n",
    "      \"Note: Theoretically a predictor can be set, but no valid argument could be found during testing.\",\n",
    "      \"Per the documentation: \\\"predictor: Hypothesis class for the Learner. Supports LR, SVM, KR, Trees\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prejudice Remover Regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 0:01:31.190817 (hr:mn:sc)\n"
     ]
    }
   ],
   "source": [
    "from aif360.algorithms.inprocessing import prejudice_remover\n",
    "aif_prr_model = prejudice_remover.PrejudiceRemover(sensitive_attr='LANGUAGE_ENGL')\n",
    "start_time = check_timer()\n",
    "aif_prr_model.fit(los_dataset)\n",
    "yhat_aif_prr = aif_prr_model.predict(los_dataset)\n",
    "print(\"Model finished in\", check_timer(start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial Debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/christineallen/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:137: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/christineallen/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:141: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/christineallen/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:84: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /Users/christineallen/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:89: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/christineallen/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/christineallen/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:159: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/christineallen/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:161: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/christineallen/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:165: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/christineallen/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:187: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "epoch 0; iter: 0; batch classifier loss: 0.734759\n",
      "epoch 1; iter: 0; batch classifier loss: 0.439836\n",
      "epoch 2; iter: 0; batch classifier loss: 0.426588\n",
      "epoch 3; iter: 0; batch classifier loss: 0.511115\n",
      "epoch 4; iter: 0; batch classifier loss: 0.426629\n",
      "epoch 5; iter: 0; batch classifier loss: 0.382949\n",
      "epoch 6; iter: 0; batch classifier loss: 0.395555\n",
      "epoch 7; iter: 0; batch classifier loss: 0.346854\n",
      "epoch 8; iter: 0; batch classifier loss: 0.372676\n",
      "epoch 9; iter: 0; batch classifier loss: 0.335853\n",
      "epoch 10; iter: 0; batch classifier loss: 0.246608\n",
      "epoch 11; iter: 0; batch classifier loss: 0.275188\n",
      "epoch 12; iter: 0; batch classifier loss: 0.328911\n",
      "epoch 13; iter: 0; batch classifier loss: 0.241372\n",
      "epoch 14; iter: 0; batch classifier loss: 0.236086\n",
      "epoch 15; iter: 0; batch classifier loss: 0.252308\n",
      "epoch 16; iter: 0; batch classifier loss: 0.178509\n",
      "epoch 17; iter: 0; batch classifier loss: 0.249029\n",
      "epoch 18; iter: 0; batch classifier loss: 0.198050\n",
      "epoch 19; iter: 0; batch classifier loss: 0.195144\n",
      "epoch 20; iter: 0; batch classifier loss: 0.164097\n",
      "epoch 21; iter: 0; batch classifier loss: 0.140235\n",
      "epoch 22; iter: 0; batch classifier loss: 0.124445\n",
      "epoch 23; iter: 0; batch classifier loss: 0.106921\n",
      "epoch 24; iter: 0; batch classifier loss: 0.119767\n",
      "epoch 25; iter: 0; batch classifier loss: 0.123019\n",
      "epoch 26; iter: 0; batch classifier loss: 0.177132\n",
      "epoch 27; iter: 0; batch classifier loss: 0.135887\n",
      "epoch 28; iter: 0; batch classifier loss: 0.106302\n",
      "epoch 29; iter: 0; batch classifier loss: 0.117987\n",
      "epoch 30; iter: 0; batch classifier loss: 0.152223\n",
      "epoch 31; iter: 0; batch classifier loss: 0.171153\n",
      "epoch 32; iter: 0; batch classifier loss: 0.106812\n",
      "epoch 33; iter: 0; batch classifier loss: 0.082483\n",
      "epoch 34; iter: 0; batch classifier loss: 0.096164\n",
      "epoch 35; iter: 0; batch classifier loss: 0.070893\n",
      "epoch 36; iter: 0; batch classifier loss: 0.080958\n",
      "epoch 37; iter: 0; batch classifier loss: 0.074488\n",
      "epoch 38; iter: 0; batch classifier loss: 0.065352\n",
      "epoch 39; iter: 0; batch classifier loss: 0.073393\n",
      "epoch 40; iter: 0; batch classifier loss: 0.092590\n",
      "epoch 41; iter: 0; batch classifier loss: 0.060138\n",
      "epoch 42; iter: 0; batch classifier loss: 0.073429\n",
      "epoch 43; iter: 0; batch classifier loss: 0.054151\n",
      "epoch 44; iter: 0; batch classifier loss: 0.091769\n",
      "epoch 45; iter: 0; batch classifier loss: 0.065830\n",
      "epoch 46; iter: 0; batch classifier loss: 0.072911\n",
      "epoch 47; iter: 0; batch classifier loss: 0.066504\n",
      "epoch 48; iter: 0; batch classifier loss: 0.048258\n",
      "epoch 49; iter: 0; batch classifier loss: 0.063621\n",
      "Model finished in 0:00:21.183605 (hr:mn:sc)\n"
     ]
    }
   ],
   "source": [
    "from aif360.algorithms.inprocessing import adversarial_debiasing\n",
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.compat.v1.Session()\n",
    "\n",
    "aif_adb_model = adversarial_debiasing.AdversarialDebiasing(privileged_groups = [{'LANGUAGE_ENGL': 1}], \n",
    "                                                           unprivileged_groups = [{'LANGUAGE_ENGL': 0}],\n",
    "                                                             scope_name='plain_classifier',\n",
    "                                                          debias=False,\n",
    "                                                          sess=sess)\n",
    "start_time = check_timer()\n",
    "aif_adb_model.fit(los_dataset)\n",
    "yhat_aifadb = aif_adb_model.predict(los_dataset)\n",
    "print(\"Model finished in\", check_timer(start_time))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other AIF360 Fairness-Aware Options that are Not Yet Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta_fair_classifier failed to converge in testing\n"
     ]
    }
   ],
   "source": [
    "from aif360.algorithms.inprocessing import meta_fair_classifier\n",
    "aif_mfc_model = meta_fair_classifier.MetaFairClassifier(sensitive_attr='LANGUAGE_ENGL')\n",
    "#aif_mfc_model.fit(los_dataset)\n",
    "#yhat_aifmfc = aif_mfc_model.predict(los_dataset)\n",
    "print(\"meta_fair_classifier failed to converge in testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Part 2.3 - FairLearn Fairness-Aware  (In-Process) Models <a class=\"anchor\" id=\"part2.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.reductions import GridSearch, ExponentiatedGradient\n",
    "from fairlearn.reductions import EqualizedOdds, DemographicParity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search with LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 0:01:06.075871 (hr:mn:sc)\n",
      "\n",
      " Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " LOS <= mean       0.73      0.91      0.81      4531\n",
      "  LOS > mean       0.76      0.47      0.58      2873\n",
      "\n",
      "    accuracy                           0.74      7404\n",
      "   macro avg       0.74      0.69      0.69      7404\n",
      "weighted avg       0.74      0.74      0.72      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train GridSearch\n",
    "gs_lgb_model = GridSearch(lgb.LGBMClassifier(**lgb_params),\n",
    "                           constraints=EqualizedOdds(),\n",
    "                           grid_size=50)\n",
    "\n",
    "start_time = check_timer()\n",
    "gs_lgb_model.fit(X_train, y_train, sensitive_features=X_train['LANGUAGE_ENGL'])\n",
    "y_pred_gs_lgb = gs_lgb_model.predict(X_test)\n",
    "print(\"Model finished in\", check_timer(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_gs_lgb, target_names=['LOS <= mean', 'LOS > mean']) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search  with XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 1:22:50.390551 (hr:mn:sc)\n",
      "\n",
      " Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " LOS <= mean       0.79      0.88      0.83      4531\n",
      "  LOS > mean       0.77      0.63      0.70      2873\n",
      "\n",
      "    accuracy                           0.78      7404\n",
      "   macro avg       0.78      0.76      0.76      7404\n",
      "weighted avg       0.78      0.78      0.78      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train GridSearch\n",
    "gs_xgb_model = GridSearch(XGBClassifier(**xgb_params),\n",
    "                   constraints=EqualizedOdds(),\n",
    "                   grid_size=50)\n",
    "\n",
    "start_time = check_timer()\n",
    "gs_xgb_model.fit(X_train, y_train, sensitive_features=X_train['LANGUAGE_ENGL'])\n",
    "y_pred_gs_xgb = gs_xgb_model.predict(X_test)\n",
    "print(\"Model finished in\", check_timer(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_gs_xgb, target_names=['LOS <= mean', 'LOS > mean']) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search on Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 0:04:47.611597 (hr:mn:sc)\n",
      "\n",
      " Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " LOS <= mean       0.75      0.91      0.82      4531\n",
      "  LOS > mean       0.79      0.53      0.63      2873\n",
      "\n",
      "    accuracy                           0.76      7404\n",
      "   macro avg       0.77      0.72      0.73      7404\n",
      "weighted avg       0.77      0.76      0.75      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train GridSearch\n",
    "gs_rfEO_model = GridSearch(RandomForestClassifier(**rf_params),\n",
    "                   constraints=EqualizedOdds(),\n",
    "                   grid_size=50)\n",
    "\n",
    "start_time = check_timer()\n",
    "gs_rfEO_model.fit(X_train, y_train, sensitive_features=X_train['LANGUAGE_ENGL'])\n",
    "y_pred_gs_rfEO = gs_rfEO_model.predict(X_test)\n",
    "print(\"Model finished in\", check_timer(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_gs_rfEO, target_names=['LOS <= mean', 'LOS > mean']) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 0:05:11.359366 (hr:mn:sc)\n",
      "\n",
      " Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " LOS <= mean       0.74      0.92      0.82      4531\n",
      "  LOS > mean       0.79      0.49      0.60      2873\n",
      "\n",
      "    accuracy                           0.75      7404\n",
      "   macro avg       0.76      0.70      0.71      7404\n",
      "weighted avg       0.76      0.75      0.73      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train GridSearch\n",
    "gs_rfDP_model = GridSearch(RandomForestClassifier(**rf_params),\n",
    "                           constraints=DemographicParity(),\n",
    "                           grid_size=50)\n",
    "\n",
    "start_time = check_timer()\n",
    "gs_rfDP_model.fit(X_train, y_train, sensitive_features=X_train['LANGUAGE_ENGL'])\n",
    "y_pred_gs_rfDP = gs_rfDP_model.predict(X_test)\n",
    "print(\"Model finished in\", check_timer(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_gs_rfDP, target_names=['LOS <= mean', 'LOS > mean']) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponentiated Gradient\n",
    "\n",
    "In progress..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " LOS <= mean       0.73      0.90      0.81      4531\n",
      "  LOS > mean       0.76      0.47      0.58      2873\n",
      "\n",
      "    accuracy                           0.74      7404\n",
      "   macro avg       0.74      0.69      0.69      7404\n",
      "weighted avg       0.74      0.74      0.72      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)  # set seed for consistent results with ExponentiatedGradient\n",
    "eg_lgb_model = ExponentiatedGradient(lgb.LGBMClassifier(**lgb_params), \n",
    "                                     constraints=DemographicParity())\n",
    "eg_lgb_model.fit(X_train, y_train, sensitive_features=X_train['LANGUAGE_ENGL'])\n",
    "y_pred_eg_lgb = eg_lgb_model.predict(X_test)\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_eg_lgb, target_names=['LOS <= mean', 'LOS > mean']) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " LOS <= mean       0.75      0.91      0.82      4531\n",
      "  LOS > mean       0.78      0.51      0.62      2873\n",
      "\n",
      "    accuracy                           0.75      7404\n",
      "   macro avg       0.76      0.71      0.72      7404\n",
      "weighted avg       0.76      0.75      0.74      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)  # set seed for consistent results with ExponentiatedGradient\n",
    "eg_rf_model = ExponentiatedGradient(RandomForestClassifier(**rf_params), \n",
    "                                    constraints=DemographicParity())  #NOTE: this may alter the model; TODO: test to determine if this is true\n",
    "eg_rf_model.fit(X_train, y_train, sensitive_features=X_train['LANGUAGE_ENGL'])\n",
    "y_pred_eg_rf = eg_rf_model.predict(X_test)\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_eg_rf, target_names=['LOS <= mean', 'LOS > mean']) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Part 2.4 - Other Methods <a class=\"anchor\" id=\"part2.4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical Risk Minimization (Fair_ERM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_FERM:\n",
    "    \"\"\" Fairness-Aware Classifier from https://github.com/jmikko/fair_ERM/blob/master/linear_ferm.py\n",
    "    \"\"\"\n",
    "    # The linear FERM algorithm\n",
    "    def __init__(self, dataset, model, sensible_feature):\n",
    "        self.dataset = dataset\n",
    "        self.values_of_sensible_feature = list(set(sensible_feature))\n",
    "        self.list_of_sensible_feature_train = sensible_feature\n",
    "        self.val0 = np.min(self.values_of_sensible_feature)\n",
    "        self.val1 = np.max(self.values_of_sensible_feature)\n",
    "        self.model = model\n",
    "        self.u = None\n",
    "        self.max_i = None\n",
    "\n",
    "    def new_representation(self, examples):\n",
    "        if self.u is None:\n",
    "            sys.exit('Model not trained yet!')\n",
    "            return 0\n",
    "\n",
    "        new_examples = np.array([ex - self.u * (ex[self.max_i] / self.u[self.max_i]) for ex in examples])\n",
    "        new_examples = np.delete(new_examples, self.max_i, 1)\n",
    "        return new_examples\n",
    "\n",
    "    def predict(self, examples):\n",
    "        new_examples = self.new_representation(examples)\n",
    "        prediction = self.model.predict(new_examples)\n",
    "        return prediction\n",
    "\n",
    "    def fit(self):\n",
    "        # Evaluation of the empirical averages among the groups\n",
    "        tmp = [ex for idx, ex in enumerate(self.dataset.data)\n",
    "               if self.dataset.target[idx] == 1 and self.list_of_sensible_feature_train[idx] == self.val1]\n",
    "        average_A_1 = np.mean(tmp, 0)\n",
    "        tmp = [ex for idx, ex in enumerate(self.dataset.data)\n",
    "               if self.dataset.target[idx] == 1 and self.list_of_sensible_feature_train[idx] == self.val0]\n",
    "        average_not_A_1 = np.mean(tmp, 0)\n",
    "\n",
    "        # Evaluation of the vector u (difference among the two averages)\n",
    "        self.u = -(average_A_1 - average_not_A_1)\n",
    "        self.max_i = np.argmax(self.u)\n",
    "\n",
    "        # Application of the new representation\n",
    "        newdata = np.array([ex - self.u * (ex[self.max_i] / self.u[self.max_i]) for ex in self.dataset.data])\n",
    "        newdata = np.delete(newdata, self.max_i, 1)\n",
    "        self.dataset = namedtuple('_', 'data, target')(newdata, self.dataset.target)\n",
    "\n",
    "        # Fitting the linear model by using the new data\n",
    "        if self.model:\n",
    "            self.model.fit(self.dataset.data, self.dataset.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " LOS <= mean       0.79      0.88      0.83      4531\n",
      "  LOS > mean       0.76      0.63      0.69      2873\n",
      "\n",
      "    accuracy                           0.78      7404\n",
      "   macro avg       0.77      0.75      0.76      7404\n",
      "weighted avg       0.78      0.78      0.77      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "import copy\n",
    "\n",
    "\n",
    "train_dataset = namedtuple('_', 'data, target')(X_train.to_numpy(), y_train.to_numpy())\n",
    "test_dataset = namedtuple('_', 'data, target')(X_test.to_numpy(), y_test.to_numpy())\n",
    "\n",
    "# predictor must be trained (or otherwise have attribute 'estimators_'); predictor may be altered by the fit process (TODO: check this)\n",
    "lr_predictor = copy.deepcopy(lr_model)\n",
    "ermL_lr_model = Linear_FERM(train_dataset, lr_predictor, X_train['LANGUAGE_ENGL'].to_numpy())  \n",
    "ermL_lr_model.fit()\n",
    "y_pred_ermL_lr = ermL_lr_model.predict(test_dataset.data)\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_ermL_lr, target_names=['LOS <= mean', 'LOS > mean']) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " LOS <= mean       0.78      0.89      0.83      4531\n",
      "  LOS > mean       0.77      0.61      0.68      2873\n",
      "\n",
      "    accuracy                           0.78      7404\n",
      "   macro avg       0.78      0.75      0.75      7404\n",
      "weighted avg       0.78      0.78      0.77      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# predictor must be trained (or otherwise have attribute 'estimators_'); predictor may be altered by the fit process (TODO: check this)\n",
    "svm_predictor = copy.deepcopy(svm_model)\n",
    "ermL_svm_model = Linear_FERM(train_dataset, svm_predictor, X_train['LANGUAGE_ENGL'].to_numpy())  \n",
    "ermL_svm_model.fit()\n",
    "y_pred_ermL_svm = ermL_svm_model.predict(test_dataset.data)\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_ermL_svm, target_names=['LOS <= mean', 'LOS > mean']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'load_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-10fcef702a20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mload_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_adult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmeasures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mequalized_odds_measure_TP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'load_data'"
     ]
    }
   ],
   "source": [
    "from load_data import load_adult\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from measures import equalized_odds_measure_TP\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from cvxopt import matrix\n",
    "import numpy as np\n",
    "from numpy import linalg\n",
    "import cvxopt\n",
    "import cvxopt.solvers\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "\n",
    "# Definition of different kernels\n",
    "def linear_kernel(x1, x2):\n",
    "    return np.dot(x1, np.transpose(x2))\n",
    "\n",
    "def gaussian_kernel(x, y, gamma=0.1):\n",
    "    return np.exp(-gamma * (linalg.norm(x - y)**2))\n",
    "\n",
    "\n",
    "class FERM(BaseEstimator):\n",
    "    # FERM algorithm\n",
    "    def __init__(self, kernel='rbf', C=1.0, sensible_feature=None, gamma=1.0):\n",
    "        self.kernel = kernel\n",
    "        self.C = C\n",
    "        self.fairness = False if sensible_feature is None else True\n",
    "        self.sensible_feature = sensible_feature\n",
    "        self.gamma = gamma\n",
    "        self.w = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if self.kernel == 'rbf':\n",
    "            self.fkernel = lambda x, y: rbf_kernel(x, y, self.gamma)\n",
    "        elif self.kernel == 'linear':\n",
    "            self.fkernel = linear_kernel\n",
    "        else:\n",
    "            self.fkernel = linear_kernel\n",
    "\n",
    "        if self.fairness:\n",
    "            self.values_of_sensible_feature = list(set(self.sensible_feature))\n",
    "            self.list_of_sensible_feature_train = self.sensible_feature\n",
    "            self.val0 = np.min(self.values_of_sensible_feature)\n",
    "            self.val1 = np.max(self.values_of_sensible_feature)\n",
    "            self.set_A1 = [idx for idx, ex in enumerate(X) if y[idx] == 1\n",
    "                           and self.sensible_feature[idx] == self.val1]\n",
    "            self.set_not_A1 = [idx for idx, ex in enumerate(X) if y[idx] == 1\n",
    "                               and self.sensible_feature[idx] == self.val0]\n",
    "            # print('self.val0:', self.val0)\n",
    "            # print('self.val1:', self.val1)\n",
    "            # print('(y, self.sensible_feature):')\n",
    "            # for el in zip(y, self.sensible_feature):\n",
    "            #     print(el)\n",
    "            self.set_1 = [idx for idx, ex in enumerate(X) if y[idx] == 1]\n",
    "            self.n_A1 = len(self.set_A1)\n",
    "            self.n_not_A1 = len(self.set_not_A1)\n",
    "            self.n_1 = len(self.set_1)\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Gram matrix\n",
    "        K = self.fkernel(X, X)\n",
    "\n",
    "        P = cvxopt.matrix(np.outer(y, y) * K)\n",
    "        q = cvxopt.matrix(np.ones(n_samples) * -1)\n",
    "        # print(y)\n",
    "        A = cvxopt.matrix(y.astype(np.double), (1, n_samples), 'd')\n",
    "        b = cvxopt.matrix(0.0)\n",
    "\n",
    "        if self.C is None:\n",
    "            G = cvxopt.matrix(np.diag(np.ones(n_samples) * -1))\n",
    "            h = cvxopt.matrix(np.zeros(n_samples))\n",
    "        else:\n",
    "            tmp1 = np.diag(np.ones(n_samples) * -1)\n",
    "            tmp2 = np.identity(n_samples)\n",
    "            G = cvxopt.matrix(np.vstack((tmp1, tmp2)))\n",
    "            tmp1 = np.zeros(n_samples)\n",
    "            tmp2 = np.ones(n_samples) * self.C\n",
    "            h = cvxopt.matrix(np.hstack((tmp1, tmp2)))\n",
    "\n",
    "        # Stack the fairness constraint\n",
    "        if self.fairness:\n",
    "            tau = [(np.sum(K[self.set_A1, idx]) / self.n_A1) - (np.sum(K[self.set_not_A1, idx]) / self.n_not_A1)\n",
    "                   for idx in range(len(y))]\n",
    "            # print('self.n_A1:', self.n_A1)\n",
    "            # print('self.n_not_A1:', self.n_not_A1)\n",
    "            # print('tau:', tau)\n",
    "            fairness_line = matrix(y * tau, (1, n_samples), 'd')\n",
    "            A = cvxopt.matrix(np.vstack([A, fairness_line]))\n",
    "            b = cvxopt.matrix([0.0, 0.0])\n",
    "\n",
    "        # solve QP problem\n",
    "        cvxopt.solvers.options['show_progress'] = False\n",
    "        # print('A:', A)\n",
    "        # print('Rank(A):', np.linalg.matrix_rank(A))\n",
    "        # print('Rank([P; A; G])', np.linalg.matrix_rank(np.vstack([P, A, G])))\n",
    "        solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "\n",
    "        # Lagrange multipliers\n",
    "        a = np.ravel(solution['x'])\n",
    "\n",
    "        # Support vectors have non zero lagrange multipliers\n",
    "        sv = a > 1e-7\n",
    "        ind = np.arange(len(a))[sv]\n",
    "        self.a = a[sv]\n",
    "        self.sv = X[sv]\n",
    "        self.sv_y = y[sv]\n",
    "        # print(\"%d support vectors out of %d points\" % (len(self.a), n_samples))\n",
    "\n",
    "        # Intercept\n",
    "        self.b = 0\n",
    "        for n in range(len(self.a)):\n",
    "            self.b += self.sv_y[n]\n",
    "            self.b -= np.sum(self.a * self.sv_y * K[ind[n], sv])\n",
    "        self.b /= len(self.a)\n",
    "\n",
    "        # Weight vector\n",
    "        if self.kernel == linear_kernel:\n",
    "            self.w = np.zeros(n_features)\n",
    "            for n in range(len(self.a)):\n",
    "                self.w += self.a[n] * self.sv_y[n] * self.sv[n]\n",
    "        else:\n",
    "            self.w = None\n",
    "\n",
    "    def project(self, X):\n",
    "        if self.w is not None:\n",
    "            return np.dot(X, self.w) + self.b\n",
    "        else:\n",
    "            XSV = self.fkernel(X, self.sv)\n",
    "            a_sv_y = np.multiply(self.a, self.sv_y)\n",
    "            y_predict = [np.sum(np.multiply(np.multiply(self.a, self.sv_y), XSV[i, :])) for i in range(len(X))]\n",
    "\n",
    "            return y_predict + self.b\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        return self.project(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(self.project(X))\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        predict = self.predict(X_test)\n",
    "        acc = accuracy_score(y_test, predict)\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'C': [0.1, 1, 10.0],\n",
    "                       'gamma': [0.1, 0.01],\n",
    "                       'kernel': ['rbf']}\n",
    "                      ]\n",
    "\n",
    "\n",
    "# predictor must be trained (or otherwise have attribute 'estimators_'); predictor may be altered by the fit process (TODO: check this)\n",
    "svm_predictor = copy.deepcopy(svm_model)\n",
    "\n",
    "algorithm = FERM(sensible_feature=train_dataset.data[:, sensible_feature])\n",
    "clf = GridSearchCV(algorithm, param_grid, n_jobs=1)\n",
    "clf.fit(dataset_train.data, dataset_train.target)\n",
    "print('Best Fair Estimator:', clf.best_estimator_)\n",
    "\n",
    "# Accuracy and Fairness\n",
    "y_predict = clf.predict(dataset_test.data)\n",
    "pred = clf.predict(dataset_test.data)\n",
    "pred_train = clf.predict(dataset_train.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Part 3 - Comparing Models <a class=\"anchor\" id=\"part3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_models = {'naive_bayes_model':nb_model, 'decision_tree_model':dt_model}\n",
    "linear_models = {'lr_model':lr_model, 'ermL_lr_model':ermL_lr_model, 'svm_model':svm_model, 'ermL_svm_model':ermL_svm_model}\n",
    "boosted_models = {'xgboost_model':xgb_model, 'gs_xgb_model':gs_xgb_model, 'lgbm_model':lgb_model, 'gs_lgbm_model':gs_lgb_model}\n",
    "rf_models ={'rf_model':rf_model, 'gs_rfEO_model':gs_rfEO_model, 'gs_rfDP_model':gs_rfDP_model, 'eg_rf_model':eg_rf_model, 'ermL_rf_model':ermL_rf_model}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FairMLHealth Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failure predicting probabilities for ermL_lr_model. Related metrics will be skipped.\n",
      "Failure predicting probabilities for svm_model. Related metrics will be skipped.\n",
      "Failure predicting probabilities for ermL_svm_model. Related metrics will be skipped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_model</th>\n",
       "      <th>ermL_lr_model</th>\n",
       "      <th>svm_model</th>\n",
       "      <th>ermL_svm_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>** Group Fairness **</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statistical Parity Difference</th>\n",
       "      <td>0.0588</td>\n",
       "      <td>0.0398</td>\n",
       "      <td>0.0739</td>\n",
       "      <td>0.0443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disparate Impact Ratio</th>\n",
       "      <td>1.2011</td>\n",
       "      <td>1.1327</td>\n",
       "      <td>1.2087</td>\n",
       "      <td>1.1551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demographic Parity Difference</th>\n",
       "      <td>0.0588</td>\n",
       "      <td>0.0398</td>\n",
       "      <td>0.0739</td>\n",
       "      <td>0.0443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demographic Parity Ratio</th>\n",
       "      <td>0.8326</td>\n",
       "      <td>0.8828</td>\n",
       "      <td>0.8273</td>\n",
       "      <td>0.8657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Odds Difference</th>\n",
       "      <td>0.0297</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0432</td>\n",
       "      <td>0.0151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equal Opportunity Difference</th>\n",
       "      <td>0.0283</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equalized Odds Difference</th>\n",
       "      <td>0.0311</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equalized Odds Ratio</th>\n",
       "      <td>0.7814</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.7799</td>\n",
       "      <td>0.8465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive Predictive Parity Difference</th>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0275</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced Accuracy Difference</th>\n",
       "      <td>-0.0014</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>-0.0032</td>\n",
       "      <td>-0.0042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC Difference</th>\n",
       "      <td>-0.0044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>** Individual Fairness **</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consistency Score</th>\n",
       "      <td>0.7786</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.7846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Between-Group Generalized Entropy Error</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>** Model Performance **</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.7611</td>\n",
       "      <td>0.7623</td>\n",
       "      <td>0.7088</td>\n",
       "      <td>0.7704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.6255</td>\n",
       "      <td>0.6251</td>\n",
       "      <td>0.7083</td>\n",
       "      <td>0.6074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.6867</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.7086</td>\n",
       "      <td>0.6793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.7785</td>\n",
       "      <td>0.7789</td>\n",
       "      <td>0.7739</td>\n",
       "      <td>0.7774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        lr_model ermL_lr_model svm_model  \\\n",
       "** Group Fairness **                                                       \n",
       "Statistical Parity Difference             0.0588        0.0398    0.0739   \n",
       "Disparate Impact Ratio                    1.2011        1.1327    1.2087   \n",
       "Demographic Parity Difference             0.0588        0.0398    0.0739   \n",
       "Demographic Parity Ratio                  0.8326        0.8828    0.8273   \n",
       "Average Odds Difference                   0.0297        0.0105    0.0432   \n",
       "Equal Opportunity Difference              0.0283        0.0081      0.04   \n",
       "Equalized Odds Difference                 0.0311        0.0128    0.0464   \n",
       "Equalized Odds Ratio                      0.7814         0.902    0.7799   \n",
       "Positive Predictive Parity Difference     0.0075        0.0275    0.0104   \n",
       "Balanced Accuracy Difference             -0.0014       -0.0024   -0.0032   \n",
       "AUC Difference                           -0.0044           NaN       NaN   \n",
       "** Individual Fairness **                                                  \n",
       "Consistency Score                         0.7786        0.7782     0.742   \n",
       "Between-Group Generalized Entropy Error        0             0         0   \n",
       "** Model Performance **                                                    \n",
       "Precision                                 0.7611        0.7623    0.7088   \n",
       "Recall                                    0.6255        0.6251    0.7083   \n",
       "F1-Score                                  0.6867        0.6869    0.7086   \n",
       "Accuracy                                  0.7785        0.7789    0.7739   \n",
       "\n",
       "                                        ermL_svm_model  \n",
       "** Group Fairness **                                    \n",
       "Statistical Parity Difference                   0.0443  \n",
       "Disparate Impact Ratio                          1.1551  \n",
       "Demographic Parity Difference                   0.0443  \n",
       "Demographic Parity Ratio                        0.8657  \n",
       "Average Odds Difference                         0.0151  \n",
       "Equal Opportunity Difference                    0.0109  \n",
       "Equalized Odds Difference                       0.0193  \n",
       "Equalized Odds Ratio                            0.8465  \n",
       "Positive Predictive Parity Difference           0.0166  \n",
       "Balanced Accuracy Difference                   -0.0042  \n",
       "AUC Difference                                     NaN  \n",
       "** Individual Fairness **                               \n",
       "Consistency Score                               0.7846  \n",
       "Between-Group Generalized Entropy Error              0  \n",
       "** Model Performance **                                 \n",
       "Precision                                       0.7704  \n",
       "Recall                                          0.6074  \n",
       "F1-Score                                        0.6793  \n",
       "Accuracy                                        0.7774  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_comparison.compare_models(X_test, y_test, X_test['LANGUAGE_ENGL'], linear_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naive_bayes_model</th>\n",
       "      <th>decision_tree_model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Measure</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>** Group Fairness **</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statistical Parity Difference</th>\n",
       "      <td>-0.0163</td>\n",
       "      <td>0.0271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disparate Impact Ratio</th>\n",
       "      <td>0.9564</td>\n",
       "      <td>1.0757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demographic Parity Difference</th>\n",
       "      <td>0.0163</td>\n",
       "      <td>0.0271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demographic Parity Ratio</th>\n",
       "      <td>0.9564</td>\n",
       "      <td>0.9296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Odds Difference</th>\n",
       "      <td>-0.0482</td>\n",
       "      <td>0.0096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equal Opportunity Difference</th>\n",
       "      <td>-0.0747</td>\n",
       "      <td>0.0088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equalized Odds Difference</th>\n",
       "      <td>0.0747</td>\n",
       "      <td>0.0104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equalized Odds Ratio</th>\n",
       "      <td>0.8901</td>\n",
       "      <td>0.9598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive Predictive Parity Difference</th>\n",
       "      <td>0.0518</td>\n",
       "      <td>0.0528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced Accuracy Difference</th>\n",
       "      <td>-0.0266</td>\n",
       "      <td>-0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC Difference</th>\n",
       "      <td>-0.0189</td>\n",
       "      <td>-0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>** Individual Fairness **</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consistency Score</th>\n",
       "      <td>0.7784</td>\n",
       "      <td>0.7095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Between-Group Generalized Entropy Error</th>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>** Model Performance **</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.6799</td>\n",
       "      <td>0.5811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.6432</td>\n",
       "      <td>0.5552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.6611</td>\n",
       "      <td>0.5678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.7441</td>\n",
       "      <td>0.6721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        naive_bayes_model decision_tree_model\n",
       "Measure                                                                      \n",
       "** Group Fairness **                                                         \n",
       "Statistical Parity Difference                     -0.0163              0.0271\n",
       "Disparate Impact Ratio                             0.9564              1.0757\n",
       "Demographic Parity Difference                      0.0163              0.0271\n",
       "Demographic Parity Ratio                           0.9564              0.9296\n",
       "Average Odds Difference                           -0.0482              0.0096\n",
       "Equal Opportunity Difference                      -0.0747              0.0088\n",
       "Equalized Odds Difference                          0.0747              0.0104\n",
       "Equalized Odds Ratio                               0.8901              0.9598\n",
       "Positive Predictive Parity Difference              0.0518              0.0528\n",
       "Balanced Accuracy Difference                      -0.0266             -0.0008\n",
       "AUC Difference                                    -0.0189             -0.0008\n",
       "** Individual Fairness **                                                    \n",
       "Consistency Score                                  0.7784              0.7095\n",
       "Between-Group Generalized Entropy Error            0.0007              0.0001\n",
       "** Model Performance **                                                      \n",
       "Precision                                          0.6799              0.5811\n",
       "Recall                                             0.6432              0.5552\n",
       "F1-Score                                           0.6611              0.5678\n",
       "Accuracy                                           0.7441              0.6721"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_comparison.compare_models(X_test, y_test, X_test['LANGUAGE_ENGL'], common_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aif_gf_model</th>\n",
       "      <th>aif_prr_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Disparate Impact Ratio</th>\n",
       "      <td>1.212619</td>\n",
       "      <td>1.208887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statistical Parity Difference</th>\n",
       "      <td>0.057558</td>\n",
       "      <td>0.062899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Odds Difference</th>\n",
       "      <td>0.030190</td>\n",
       "      <td>0.034180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equal Opportunity Difference</th>\n",
       "      <td>0.037543</td>\n",
       "      <td>0.043702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced Accuracy Difference</th>\n",
       "      <td>0.757601</td>\n",
       "      <td>0.773845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Between-Group Coefficient of Variation</th>\n",
       "      <td>0.000908</td>\n",
       "      <td>0.004872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Theil Index</th>\n",
       "      <td>0.186016</td>\n",
       "      <td>0.165591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        aif_gf_model  aif_prr_model\n",
       "Disparate Impact Ratio                      1.212619       1.208887\n",
       "Statistical Parity Difference               0.057558       0.062899\n",
       "Average Odds Difference                     0.030190       0.034180\n",
       "Equal Opportunity Difference                0.037543       0.043702\n",
       "Balanced Accuracy Difference                0.757601       0.773845\n",
       "Between-Group Coefficient of Variation      0.000908       0.004872\n",
       "Theil Index                                 0.186016       0.165591"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aif_dataset_measures(dataset=los_dataset, \n",
    "                       models={'aif_gf_model':aif_gf_model, 'aif_prr_model':aif_prr_model}) #, 'aif_adb_model':aif_adb_model })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xgboost_model</th>\n",
       "      <th>gs_xgb_model</th>\n",
       "      <th>lgbm_model</th>\n",
       "      <th>gs_lgbm_model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Measure</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>** Group Fairness **</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statistical Parity Difference</th>\n",
       "      <td>0.0622</td>\n",
       "      <td>0.0622</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disparate Impact Ratio</th>\n",
       "      <td>1.2134</td>\n",
       "      <td>1.2134</td>\n",
       "      <td>1.1392</td>\n",
       "      <td>1.1392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demographic Parity Difference</th>\n",
       "      <td>0.0622</td>\n",
       "      <td>0.0622</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demographic Parity Ratio</th>\n",
       "      <td>0.8242</td>\n",
       "      <td>0.8242</td>\n",
       "      <td>0.8778</td>\n",
       "      <td>0.8778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Odds Difference</th>\n",
       "      <td>0.0337</td>\n",
       "      <td>0.0337</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.0106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equal Opportunity Difference</th>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equalized Odds Difference</th>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equalized Odds Ratio</th>\n",
       "      <td>0.7882</td>\n",
       "      <td>0.7882</td>\n",
       "      <td>0.9261</td>\n",
       "      <td>0.9261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive Predictive Parity Difference</th>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.0356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced Accuracy Difference</th>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC Difference</th>\n",
       "      <td>-0.0005</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>** Individual Fairness **</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consistency Score</th>\n",
       "      <td>0.7816</td>\n",
       "      <td>0.7816</td>\n",
       "      <td>0.8462</td>\n",
       "      <td>0.8462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Between-Group Generalized Entropy Error</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>** Model Performance **</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.7702</td>\n",
       "      <td>0.7702</td>\n",
       "      <td>0.7591</td>\n",
       "      <td>0.7591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.6345</td>\n",
       "      <td>0.6345</td>\n",
       "      <td>0.4716</td>\n",
       "      <td>0.4716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.6958</td>\n",
       "      <td>0.6958</td>\n",
       "      <td>0.5818</td>\n",
       "      <td>0.5818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.7847</td>\n",
       "      <td>0.7847</td>\n",
       "      <td>0.7369</td>\n",
       "      <td>0.7369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        xgboost_model gs_xgb_model lgbm_model  \\\n",
       "Measure                                                                         \n",
       "** Group Fairness **                                                            \n",
       "Statistical Parity Difference                  0.0622       0.0622     0.0316   \n",
       "Disparate Impact Ratio                         1.2134       1.2134     1.1392   \n",
       "Demographic Parity Difference                  0.0622       0.0622     0.0316   \n",
       "Demographic Parity Ratio                       0.8242       0.8242     0.8778   \n",
       "Average Odds Difference                        0.0337       0.0337     0.0106   \n",
       "Equal Opportunity Difference                   0.0384       0.0384     0.0138   \n",
       "Equalized Odds Difference                      0.0384       0.0384     0.0138   \n",
       "Equalized Odds Ratio                           0.7882       0.7882     0.9261   \n",
       "Positive Predictive Parity Difference          0.0115       0.0115     0.0356   \n",
       "Balanced Accuracy Difference                   0.0047       0.0047     0.0033   \n",
       "AUC Difference                                -0.0005      -0.0005     0.0045   \n",
       "** Individual Fairness **                                                       \n",
       "Consistency Score                              0.7816       0.7816     0.8462   \n",
       "Between-Group Generalized Entropy Error             0            0     0.0001   \n",
       "** Model Performance **                                                         \n",
       "Precision                                      0.7702       0.7702     0.7591   \n",
       "Recall                                         0.6345       0.6345     0.4716   \n",
       "F1-Score                                       0.6958       0.6958     0.5818   \n",
       "Accuracy                                       0.7847       0.7847     0.7369   \n",
       "\n",
       "                                        gs_lgbm_model  \n",
       "Measure                                                \n",
       "** Group Fairness **                                   \n",
       "Statistical Parity Difference                  0.0316  \n",
       "Disparate Impact Ratio                         1.1392  \n",
       "Demographic Parity Difference                  0.0316  \n",
       "Demographic Parity Ratio                       0.8778  \n",
       "Average Odds Difference                        0.0106  \n",
       "Equal Opportunity Difference                   0.0138  \n",
       "Equalized Odds Difference                      0.0138  \n",
       "Equalized Odds Ratio                           0.9261  \n",
       "Positive Predictive Parity Difference          0.0356  \n",
       "Balanced Accuracy Difference                   0.0033  \n",
       "AUC Difference                                 0.0045  \n",
       "** Individual Fairness **                              \n",
       "Consistency Score                              0.8462  \n",
       "Between-Group Generalized Entropy Error        0.0001  \n",
       "** Model Performance **                                \n",
       "Precision                                      0.7591  \n",
       "Recall                                         0.4716  \n",
       "F1-Score                                       0.5818  \n",
       "Accuracy                                       0.7369  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_comparison.compare_models(X_test, y_test, X_test['LANGUAGE_ENGL'], boosted_models) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failure predicting probabilities for eg_rf_model. Related metrics will be skipped.\n",
      "Failure predicting probabilities for ermL_rf_model. Related metrics will be skipped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf_model</th>\n",
       "      <th>gs_rfEO_model</th>\n",
       "      <th>gs_rfDP_model</th>\n",
       "      <th>eg_rf_model</th>\n",
       "      <th>ermL_rf_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>** Group Fairness **</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statistical Parity Difference</th>\n",
       "      <td>0.0473</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>0.0617</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disparate Impact Ratio</th>\n",
       "      <td>1.1928</td>\n",
       "      <td>1.2087</td>\n",
       "      <td>1.2923</td>\n",
       "      <td>1.145</td>\n",
       "      <td>1.0891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demographic Parity Difference</th>\n",
       "      <td>0.0473</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>0.0617</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demographic Parity Ratio</th>\n",
       "      <td>0.8383</td>\n",
       "      <td>0.8273</td>\n",
       "      <td>0.7738</td>\n",
       "      <td>0.8734</td>\n",
       "      <td>0.9182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Odds Difference</th>\n",
       "      <td>0.0229</td>\n",
       "      <td>0.0265</td>\n",
       "      <td>0.0426</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>-0.0024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equal Opportunity Difference</th>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.0633</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>-0.0058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equalized Odds Difference</th>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.0633</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.0058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equalized Odds Ratio</th>\n",
       "      <td>0.8322</td>\n",
       "      <td>0.8269</td>\n",
       "      <td>0.7625</td>\n",
       "      <td>0.8337</td>\n",
       "      <td>0.9892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive Predictive Parity Difference</th>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced Accuracy Difference</th>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>-0.0081</td>\n",
       "      <td>-0.0035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC Difference</th>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>** Individual Fairness **</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consistency Score</th>\n",
       "      <td>0.818</td>\n",
       "      <td>0.8239</td>\n",
       "      <td>0.8334</td>\n",
       "      <td>0.8222</td>\n",
       "      <td>0.8147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Between-Group Generalized Entropy Error</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>** Model Performance **</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.7838</td>\n",
       "      <td>0.7851</td>\n",
       "      <td>0.7956</td>\n",
       "      <td>0.7775</td>\n",
       "      <td>0.7652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.5388</td>\n",
       "      <td>0.5252</td>\n",
       "      <td>0.4904</td>\n",
       "      <td>0.5096</td>\n",
       "      <td>0.5378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.6386</td>\n",
       "      <td>0.6294</td>\n",
       "      <td>0.6068</td>\n",
       "      <td>0.6156</td>\n",
       "      <td>0.6316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.7634</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.7534</td>\n",
       "      <td>0.7531</td>\n",
       "      <td>0.7566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        rf_model gs_rfEO_model gs_rfDP_model  \\\n",
       "** Group Fairness **                                                           \n",
       "Statistical Parity Difference             0.0473        0.0495        0.0617   \n",
       "Disparate Impact Ratio                    1.1928        1.2087        1.2923   \n",
       "Demographic Parity Difference             0.0473        0.0495        0.0617   \n",
       "Demographic Parity Ratio                  0.8383        0.8273        0.7738   \n",
       "Average Odds Difference                   0.0229        0.0265        0.0426   \n",
       "Equal Opportunity Difference              0.0284        0.0355        0.0633   \n",
       "Equalized Odds Difference                 0.0284        0.0355        0.0633   \n",
       "Equalized Odds Ratio                      0.8322        0.8269        0.7625   \n",
       "Positive Predictive Parity Difference     0.0189        0.0202        0.0164   \n",
       "Balanced Accuracy Difference              0.0054         0.009        0.0207   \n",
       "AUC Difference                            0.0035        0.0077        0.0162   \n",
       "** Individual Fairness **                                                      \n",
       "Consistency Score                          0.818        0.8239        0.8334   \n",
       "Between-Group Generalized Entropy Error        0             0             0   \n",
       "** Model Performance **                                                        \n",
       "Precision                                 0.7838        0.7851        0.7956   \n",
       "Recall                                    0.5388        0.5252        0.4904   \n",
       "F1-Score                                  0.6386        0.6294        0.6068   \n",
       "Accuracy                                  0.7634          0.76        0.7534   \n",
       "\n",
       "                                        eg_rf_model ermL_rf_model  \n",
       "** Group Fairness **                                               \n",
       "Statistical Parity Difference                0.0346        0.0234  \n",
       "Disparate Impact Ratio                        1.145        1.0891  \n",
       "Demographic Parity Difference                0.0346        0.0234  \n",
       "Demographic Parity Ratio                     0.8734        0.9182  \n",
       "Average Odds Difference                      0.0089       -0.0024  \n",
       "Equal Opportunity Difference                 0.0007       -0.0058  \n",
       "Equalized Odds Difference                     0.017        0.0058  \n",
       "Equalized Odds Ratio                         0.8337        0.9892  \n",
       "Positive Predictive Parity Difference        0.0107        0.0395  \n",
       "Balanced Accuracy Difference                -0.0081       -0.0035  \n",
       "AUC Difference                                  NaN           NaN  \n",
       "** Individual Fairness **                                          \n",
       "Consistency Score                            0.8222        0.8147  \n",
       "Between-Group Generalized Entropy Error      0.0001        0.0002  \n",
       "** Model Performance **                                            \n",
       "Precision                                    0.7775        0.7652  \n",
       "Recall                                       0.5096        0.5378  \n",
       "F1-Score                                     0.6156        0.6316  \n",
       "Accuracy                                     0.7531        0.7566  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_comparison.compare_models(X_test, y_test, X_test['LANGUAGE_ENGL'], rf_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c7d95430a449f2a5801d514c0c7b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FairlearnWidget(value={'true_y': [0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<fairlearn.widget._fairlearn_dashboard.FairlearnDashboard at 0x7fa22efaa9d0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (Optional) View this model in Fairlearn's fairness dashboard, and see the disparities which appear:\n",
    "from fairlearn.widget import FairlearnDashboard\n",
    "FairlearnDashboard(sensitive_features=X_test['LANGUAGE_ENGL'].to_list(), \n",
    "                   sensitive_feature_names=['LANGUAGE_ENGL'],\n",
    "                   y_true=y_test.iloc[:,0].to_list(),\n",
    "                   y_pred={'rf_model':list(y_pred_rf), 'gs_rfEO_model':list(y_pred_gs_rfEO), 'gs_rfDP_model':list(y_pred_gs_rfDP), 'eg_rf_model':list(y_pred_eg_rf), 'ermL_rf_model':list(y_pred_ermL_rf)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Part 4 - Save Results <a class=\"anchor\" id=\"part4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_models = rf_models\n",
    "\n",
    "packet = model_comparison.fairCompare(test_data=X_test, target_data=y_test, models=models, train_data=train_data)\n",
    "if not os.path.exists(os.path.dirname(output_file)):\n",
    "        os.makedirs(output_file)\n",
    "#dump(packet, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
