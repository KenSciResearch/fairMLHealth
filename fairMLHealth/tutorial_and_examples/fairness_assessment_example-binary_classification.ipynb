{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification Fairness Assesment Template - Example\n",
    "\n",
    "This example is a simple illustration for the use of the [Binary Classification Fairness Template](../binary_classification_fairness_template.ipynb). It compares a RandomForestClassifier against fairness-aware alternative versions. For more information about specific measures, please see the [KDD Tutorial Notebook](kdd_fairness_in_healthcare_tutorial.ipynb). \n",
    "\n",
    "## Example Contents\n",
    "\n",
    "[Part 1](#part1) - Data Loading and Model Setup\n",
    "\n",
    "[Part 2](#part2) - Fairness-Aware Models\n",
    "\n",
    "[Part 3](#part3) - Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from fairMLHealth.utils import model_comparison, helpers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(0)  # set seed for consistent results with ExponentiatedGradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Load Data and Generate Baseline Model <a name=\"part1\"></a>\n",
    "\n",
    "This example uses a data subset from the [MIMIC-III clinical database](https://mimic.physionet.org/gettingstarted/access/) to predict \"length of stay\" (LOS) value. For this example, LOS is total ICU time for a given hospital admission in patients 65 and above. The raw LOS value is then converted to a binary value specifying whether an admission's length of stay is greater than the sample mean. A baseline model is then generated using the Scikit-Learn RandomForestClassifier.\n",
    "\n",
    "Note that this set of example models was generated through a larger test of model fitness and was chosen due to its pronounced differences in scores across the fairness-aware versions that you will see shortly. For more examples of standard vs. fairness-aware classifiers for this toy problem, see [models_for_binary_classification_example.ipynb](models_for_binary_classification_example.ipynb).\n",
    "\n",
    "Note also that the code below will automatically unzip and format all necessary data for these experiments from a raw download of MIMIC-III data (saving the formatted data in the same MIMIC folder). MIMIC-III is a freely available database, however all users must pass a quick human subjects certification course. If you would like to run this example on your own, [follow these steps to be granted access to MIMIC III](https://mimic.physionet.org/gettingstarted/access/) and download the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Example models in this notebook use data from all years of the MIMIC-III dataset for patients aged 65 and older. Data are imported at the encounter level with all additional patient identification dropped. All models include an \"AGE\" feature, simplified to 5-year bins, as well as boolean diagnosis and procedure features categorized through the Clinical Classifications Software system ([HCUP](https://www.hcup-us.ahrq.gov/toolssoftware/ccs/ccs.jsp)). All features other than age are one-hot encoded and prefixed with their variable type (e.g. \"GENDER_\", \"ETHNICITY_\").  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_mimic_data_folder = \"[path to folder containing your MIMIC-III zip files]\"\n",
    "path_to_mimic_data_folder = \"~/data/MIMIC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " This data subset has 22434 total observations and 648 input features \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw Feature</th>\n",
       "      <th>Category Count (Encoded Features)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DIAGNOSIS</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ETHNICITY</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GENDER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INSURANCE</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LANGUAGE</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MARRIED</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PROCEDURE</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RELIGION</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Raw Feature  Category Count (Encoded Features)\n",
       "0         AGE                                  1\n",
       "1   DIAGNOSIS                                282\n",
       "2   ETHNICITY                                 41\n",
       "3      GENDER                                  1\n",
       "4   INSURANCE                                  5\n",
       "5    LANGUAGE                                 69\n",
       "6     MARRIED                                  7\n",
       "7   PROCEDURE                                222\n",
       "8    RELIGION                                 20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_e7f749e8_0353_11eb_8532_f0189849bf4brow0_col1,#T_e7f749e8_0353_11eb_8532_f0189849bf4brow1_col1{\n",
       "            background-color:  aquamarine;\n",
       "        }</style><table id=\"T_e7f749e8_0353_11eb_8532_f0189849bf4b\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >count</th>        <th class=\"col_heading level0 col1\" >mean</th>        <th class=\"col_heading level0 col2\" >std</th>        <th class=\"col_heading level0 col3\" >min</th>        <th class=\"col_heading level0 col4\" >25%</th>        <th class=\"col_heading level0 col5\" >50%</th>        <th class=\"col_heading level0 col6\" >75%</th>        <th class=\"col_heading level0 col7\" >max</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_e7f749e8_0353_11eb_8532_f0189849bf4blevel0_row0\" class=\"row_heading level0 row0\" >length_of_stay</th>\n",
       "                        <td id=\"T_e7f749e8_0353_11eb_8532_f0189849bf4brow0_col0\" class=\"data row0 col0\" >22434.000000</td>\n",
       "                        <td id=\"T_e7f749e8_0353_11eb_8532_f0189849bf4brow0_col1\" class=\"data row0 col1\" >9.115200</td>\n",
       "                        <td id=\"T_e7f749e8_0353_11eb_8532_f0189849bf4brow0_col2\" class=\"data row0 col2\" >6.208700</td>\n",
       "                        <td id=\"T_e7f749e8_0353_11eb_8532_f0189849bf4brow0_col3\" class=\"data row0 col3\" >0.004200</td>\n",
       "                        <td id=\"T_e7f749e8_0353_11eb_8532_f0189849bf4brow0_col4\" class=\"data row0 col4\" >4.735200</td>\n",
       "                        <td id=\"T_e7f749e8_0353_11eb_8532_f0189849bf4brow0_col5\" class=\"data row0 col5\" >7.579900</td>\n",
       "                        <td id=\"T_e7f749e8_0353_11eb_8532_f0189849bf4brow0_col6\" class=\"data row0 col6\" >12.017700</td>\n",
       "                        <td id=\"T_e7f749e8_0353_11eb_8532_f0189849bf4brow0_col7\" class=\"data row0 col7\" >29.988900</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e7f749e8_0353_11eb_8532_f0189849bf4blevel0_row1\" class=\"row_heading level0 row1\" >long_los</th>\n",
       "                        <td id=\"T_e7f749e8_0353_11eb_8532_f0189849bf4brow1_col0\" class=\"data row1 col0\" >22434.000000</td>\n",
       "                        <td id=\"T_e7f749e8_0353_11eb_8532_f0189849bf4brow1_col1\" class=\"data row1 col1\" >0.388000</td>\n",
       "                        <td id=\"T_e7f749e8_0353_11eb_8532_f0189849bf4brow1_col2\" class=\"data row1 col2\" >0.487300</td>\n",
       "                        <td id=\"T_e7f749e8_0353_11eb_8532_f0189849bf4brow1_col3\" class=\"data row1 col3\" >0.000000</td>\n",
       "                        <td id=\"T_e7f749e8_0353_11eb_8532_f0189849bf4brow1_col4\" class=\"data row1 col4\" >0.000000</td>\n",
       "                        <td id=\"T_e7f749e8_0353_11eb_8532_f0189849bf4brow1_col5\" class=\"data row1 col5\" >0.000000</td>\n",
       "                        <td id=\"T_e7f749e8_0353_11eb_8532_f0189849bf4brow1_col6\" class=\"data row1 col6\" >1.000000</td>\n",
       "                        <td id=\"T_e7f749e8_0353_11eb_8532_f0189849bf4brow1_col7\" class=\"data row1 col7\" >1.000000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ffd5f3a1b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data and subset to ages 65+\n",
    "df = helpers.load_mimic3_example(path_to_mimic_data_folder) \n",
    "df.drop('GENDER_F', axis=1, inplace=True)\n",
    "df = df.loc[df['AGE'].ge(65),:]\n",
    "helpers.print_feature_table(df)\n",
    "display(Markdown('---'))\n",
    "\n",
    "# Generate a binary target flagging whether an observation's length_of_stay value is above or below the mean. \n",
    "mean_val=df['length_of_stay'].mean()\n",
    "df['long_los'] = df['length_of_stay'].apply(lambda x: 1 if x > mean_val else 0)\n",
    "los_tbl = df[['length_of_stay', 'long_los']].describe().transpose().round(4)\n",
    "display(los_tbl.style.applymap(helpers.highlight_col, subset=pd.IndexSlice[:, 'mean']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data and Generate Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset and Split Data\n",
    "X = df.loc[:,[c for c in df.columns if c not in ['ADMIT_ID','length_of_stay', 'long_los']]]\n",
    "y = df.loc[:, ['long_los']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Random Forest Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " LOS <= mean       0.77      0.89      0.83      4531\n",
      "  LOS > mean       0.78      0.58      0.66      2873\n",
      "\n",
      "    accuracy                           0.77      7404\n",
      "   macro avg       0.77      0.74      0.74      7404\n",
      "weighted avg       0.77      0.77      0.76      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set model parameters (currently set as default values, but defined here to be explicit)\n",
    "rf_params = {'n_estimators': 1800, 'min_samples_split': 5, 'bootstrap': False}\n",
    "\n",
    "# Train Model\n",
    "rf_model = RandomForestClassifier(**rf_params)\n",
    "rf_model.fit(X_train, y_train.iloc[:,0])\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Random Forest Prediction Scores:\", \"\\n\", \n",
    "      classification_report(y_test, y_pred_rf, target_names=['LOS <= mean', 'LOS > mean']) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Fairness-Aware Models <a name=\"part2\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FairLearn Models\n",
    "\n",
    "The [FairLearn](https://fairlearn.github.io/) package includes three [mitigation algorithms](https://fairlearn.github.io/user_guide/mitigation.html) designed to increase the fairness of an existing model relative to one of two user-specified fairness metrics. Both algorithms and metrics are listed in the cell below.\n",
    "\n",
    "For more information about the specifics of these fairness metrics, see also [Part 5 of the KDD Tutorial Notebook](kdd_fairness_in_healthcare_tutorial.ipynb#part5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mitigation Algorithms\n",
    "from fairlearn.reductions import GridSearch, ExponentiatedGradient\n",
    "\n",
    "# Fairness Measures\n",
    "from fairlearn.reductions import EqualizedOdds, DemographicParity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fair ExponentiatedGradient\n",
    "\n",
    "ExponentiatedGradient is a wrapper that runs a constrained optimization on a binary classification model using the Exponentiated Gradient approach according to the fairness metric of choice. GridSearch treats the prediction as a sequence of cost-sensitive classification problems. It then returns the solution with the smallest error (constrained by the metric of choice). This approach has been demonstrated to have minimal effect on model performance by some measures. [Agarwal2018](#Agarwal2018)\n",
    "\n",
    "Applicable to categorical sensitive attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Equalized Odds as constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " LOS <= mean       0.77      0.89      0.83      4531\n",
      "  LOS > mean       0.78      0.58      0.66      2873\n",
      "\n",
      "    accuracy                           0.77      7404\n",
      "   macro avg       0.77      0.74      0.74      7404\n",
      "weighted avg       0.77      0.77      0.76      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eg_rfEO_model = ExponentiatedGradient(RandomForestClassifier(**rf_params), \n",
    "                                    constraints=EqualizedOdds())  #NOTE: this may alter the model; TODO: test to determine if this is true\n",
    "eg_rfEO_model.fit(X_train, y_train, sensitive_features=X_train['LANGUAGE_ENGL'])\n",
    "y_pred_eg_rfEO = eg_rfEO_model.predict(X_test)\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      classification_report(y_test, y_pred_eg_rfEO, target_names=['LOS <= mean', 'LOS > mean']) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Demographic Parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eg_rfDP_model = ExponentiatedGradient(RandomForestClassifier(**rf_params), \n",
    "                                    constraints=DemographicParity())  #NOTE: this may alter the model; TODO: test to determine if this is true\n",
    "eg_rfDP_model.fit(X_train, y_train, sensitive_features=X_train['LANGUAGE_ENGL'])\n",
    "y_pred_eg_rfDP = eg_rfDP_model.predict(X_test)\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      classification_report(y_test, y_pred_eg_rfDP, target_names=['LOS <= mean', 'LOS > mean']) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fair GridSearch\n",
    "\n",
    "GridSearch is a wrapper that runs a constrained optimization on a binary classification or a regression model using the Grid Search approach according to the fairness metric of choice. GridSearch treats the prediction as a sequence of cost-sensitive classification problems. It then returns the solution with the smallest error (constrained by the metric of choice). This approach has been demonstrated to have minimal effect on model performance by some measures. [Agarwal2018](#Agarwal2018)\n",
    "\n",
    "Applicable to binary sensitive attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Equalized Odds as constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GridSearch\n",
    "gs_rfEO_model = GridSearch(RandomForestClassifier(**rf_params),\n",
    "                           constraints=EqualizedOdds(),\n",
    "                           grid_size=40)\n",
    "\n",
    "gs_rfEO_model.fit(X_train, y_train, sensitive_features=X_train['LANGUAGE_ENGL'])\n",
    "y_pred_gs_rfEO = gs_rfEO_model.predict(X_test)\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      classification_report(y_test, y_pred_gs_rfEO, target_names=['LOS <= mean', 'LOS > mean']) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Demographic Parity as constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GridSearch\n",
    "gs_rfDP_model = GridSearch(RandomForestClassifier(**rf_params),\n",
    "                           constraints=DemographicParity(),\n",
    "                           grid_size=40)\n",
    "\n",
    "gs_rfDP_model.fit(X_train, y_train, sensitive_features=X_train['LANGUAGE_ENGL'])\n",
    "y_pred_gs_rfDP = gs_rfDP_model.predict(X_test)\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      classification_report(y_test, y_pred_gs_rfDP, target_names=['LOS <= mean', 'LOS > mean']) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Model Comparison <a name=\"part3\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the Required Variables  \n",
    "\n",
    "* X (numpy array or similar pandas object): test data to be passed to the models to generate predictions. It's recommended that these be separate data from those used to train the model.\n",
    "\n",
    "* y (numpy array or similar pandas object): target data array corresponding to X. It is recommended that the target is not present in the test_data.\n",
    "\n",
    "* models (list or dict-like): the set of trained models to be evaluated. Note that the dictionary keys are assumed as model names. If a list-like object is passed, the function will set model names relative to their index (i.e. \"model_0\", \"model_1\", etc.)\n",
    "\n",
    "* protected_attr (numpy array or similar pandas object): protected attributes correspoinding to X, optionally also included in X. Note that values must currently be binary- or boolean-type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_test\n",
    "y = y_test\n",
    "protected_attr = X_test['LANGUAGE_ENGL']\n",
    "models ={'rf_model':rf_model, 'gs_rfEO_model':gs_rfEO_model, 'gs_rfDP_model':gs_rfDP_model, 'eg_rfEO_model':eg_rfEO_model, 'eg_rfDP_model':eg_rfDP_model}\n",
    "print(\"Models being compared in this example:\", list(models.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with the FairMLHealth Tool\n",
    "\n",
    "The FairMLHealth model_comparison tool generates a table of fairness measures that can be used to quickly compare the fairness-performance tradeoff for a set of fairness-aware models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = model_comparison.compare_models(X, y, protected_attr, models)\n",
    "\n",
    "# Highlight Groups\n",
    "idx = pd.IndexSlice\n",
    "equal_odds = comparison.loc[idx['** Group Fairness **',\n",
    "                            ['Equal Opportunity Difference', 'Equalized Odds Difference', 'Equalized Odds Ratio']],:].index\n",
    "focus_measures = comparison.loc[idx['** Group Fairness **',\n",
    "                            ['Disparate Impact Ratio', 'Consistency Score']],:].index\n",
    "\n",
    "# Note: An HTML wrapper is used here around the .render() method to enable color rendering in GitHub. These steps are not necessary to \n",
    "#    display highlights in a standard Jupyter notebook\n",
    "table = model_comparison.highlight_suspicious_scores(comparison\n",
    "            ).apply(lambda x: ['background-color:aquamarine' if x.name in equal_odds else '' for i in x], axis=1)\n",
    "HTML(table.render())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with the FairLearn Dashboard\n",
    "\n",
    "FairLearn comes with its own model comparison dashboard to allow visual comparison between models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.widget import FairlearnDashboard\n",
    "\n",
    "# Note: for classification models, arrays must be passed as a list\n",
    "FairlearnDashboard(sensitive_features=protected_attr.to_list(), \n",
    "                   sensitive_feature_names=['LANGUAGE_ENGL'],\n",
    "                   y_true=y.iloc[:,0].to_list(),\n",
    "                   y_pred={k:model.predict(X) for k,model in models.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "<a name=\"Agarwal2018\"></a>\n",
    "Agarwal, A., Beygelzimer, A., Dud√≠k, M., Langford, J., & Wallach, H. (2018). A reductions approach to fair classification. [rXiv preprint arXiv:1803.02453](https://arxiv.org/pdf/1803.02453.pdf)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
