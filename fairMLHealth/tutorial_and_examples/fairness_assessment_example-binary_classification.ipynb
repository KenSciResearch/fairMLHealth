{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Prediction Fairness Assesment Template - Example\n",
    "\n",
    "This example is a simple illustration for the use of the [Classification Fairness Template](). It compares a RandomForestClassifier against fairness-aware alternative versions. For more information about specific measures, please see the [KDD Tutorial Notebook](kdd_fairness_in_healthcare_tutorial.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from fairMLHealth.utils import model_comparison, helpers\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Load Data and Generate Baseline Model\n",
    "\n",
    "This example uses a data subset from the [MIMIC-III clinical database](https://mimic.physionet.org/gettingstarted/access/) to predict \"length of stay\" (LOS) value. For this example, LOS is total ICU time for a given hospital admission in patients 65 and above. The raw LOS value is then converted to a binary value specifying whether an admission's length of stay is greater than the sample mean. A baseline model is then generated using the Scikit-Learn RandomForestClassifier.\n",
    "\n",
    "Note that this set of example models was generated through a larger test of model fitness and was chosen due to its pronounced differences in scores across the fairness-aware versions that you will see shortly. For more examples of standard vs. fairness-aware classifiers for this toy problem, see [models_for_binary_classification_example.ipynb](models_for_binary_classification_example.ipynb).\n",
    "\n",
    "Note also that the code below will automatically unzip and format all necessary data for these experiments from a raw download of MIMIC-III data (saving the formatted data in the same MIMIC folder). MIMIC-III is a freely available database, however all users must pass a quick human subjects certification course. If you would like to run this example on your own, [follow these steps to be granted access to MIMIC III](https://mimic.physionet.org/gettingstarted/access/) and download the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_mimic_data_folder = \"[path to folder containing your MIMIC-III zip files]\"\n",
    "path_to_mimic_data_folder = \"~/data/MIMIC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " This data subset has 22434 total observations and 648 input features \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw Feature</th>\n",
       "      <th>Category Count (Encoded Features)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DIAGNOSIS</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ETHNICITY</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GENDER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INSURANCE</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LANGUAGE</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MARRIED</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PROCEDURE</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RELIGION</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Raw Feature  Category Count (Encoded Features)\n",
       "0         AGE                                  1\n",
       "1   DIAGNOSIS                                282\n",
       "2   ETHNICITY                                 41\n",
       "3      GENDER                                  1\n",
       "4   INSURANCE                                  5\n",
       "5    LANGUAGE                                 69\n",
       "6     MARRIED                                  7\n",
       "7   PROCEDURE                                222\n",
       "8    RELIGION                                 20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_ea8ddd86_fcee_11ea_8232_f0189849bf4brow0_col1,#T_ea8ddd86_fcee_11ea_8232_f0189849bf4brow1_col1{\n",
       "            background-color:  aquamarine;\n",
       "        }</style><table id=\"T_ea8ddd86_fcee_11ea_8232_f0189849bf4b\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >count</th>        <th class=\"col_heading level0 col1\" >mean</th>        <th class=\"col_heading level0 col2\" >std</th>        <th class=\"col_heading level0 col3\" >min</th>        <th class=\"col_heading level0 col4\" >25%</th>        <th class=\"col_heading level0 col5\" >50%</th>        <th class=\"col_heading level0 col6\" >75%</th>        <th class=\"col_heading level0 col7\" >max</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_ea8ddd86_fcee_11ea_8232_f0189849bf4blevel0_row0\" class=\"row_heading level0 row0\" >length_of_stay</th>\n",
       "                        <td id=\"T_ea8ddd86_fcee_11ea_8232_f0189849bf4brow0_col0\" class=\"data row0 col0\" >22434.000000</td>\n",
       "                        <td id=\"T_ea8ddd86_fcee_11ea_8232_f0189849bf4brow0_col1\" class=\"data row0 col1\" >9.115200</td>\n",
       "                        <td id=\"T_ea8ddd86_fcee_11ea_8232_f0189849bf4brow0_col2\" class=\"data row0 col2\" >6.208700</td>\n",
       "                        <td id=\"T_ea8ddd86_fcee_11ea_8232_f0189849bf4brow0_col3\" class=\"data row0 col3\" >0.004200</td>\n",
       "                        <td id=\"T_ea8ddd86_fcee_11ea_8232_f0189849bf4brow0_col4\" class=\"data row0 col4\" >4.735200</td>\n",
       "                        <td id=\"T_ea8ddd86_fcee_11ea_8232_f0189849bf4brow0_col5\" class=\"data row0 col5\" >7.579900</td>\n",
       "                        <td id=\"T_ea8ddd86_fcee_11ea_8232_f0189849bf4brow0_col6\" class=\"data row0 col6\" >12.017700</td>\n",
       "                        <td id=\"T_ea8ddd86_fcee_11ea_8232_f0189849bf4brow0_col7\" class=\"data row0 col7\" >29.988900</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ea8ddd86_fcee_11ea_8232_f0189849bf4blevel0_row1\" class=\"row_heading level0 row1\" >long_los</th>\n",
       "                        <td id=\"T_ea8ddd86_fcee_11ea_8232_f0189849bf4brow1_col0\" class=\"data row1 col0\" >22434.000000</td>\n",
       "                        <td id=\"T_ea8ddd86_fcee_11ea_8232_f0189849bf4brow1_col1\" class=\"data row1 col1\" >0.388000</td>\n",
       "                        <td id=\"T_ea8ddd86_fcee_11ea_8232_f0189849bf4brow1_col2\" class=\"data row1 col2\" >0.487300</td>\n",
       "                        <td id=\"T_ea8ddd86_fcee_11ea_8232_f0189849bf4brow1_col3\" class=\"data row1 col3\" >0.000000</td>\n",
       "                        <td id=\"T_ea8ddd86_fcee_11ea_8232_f0189849bf4brow1_col4\" class=\"data row1 col4\" >0.000000</td>\n",
       "                        <td id=\"T_ea8ddd86_fcee_11ea_8232_f0189849bf4brow1_col5\" class=\"data row1 col5\" >0.000000</td>\n",
       "                        <td id=\"T_ea8ddd86_fcee_11ea_8232_f0189849bf4brow1_col6\" class=\"data row1 col6\" >1.000000</td>\n",
       "                        <td id=\"T_ea8ddd86_fcee_11ea_8232_f0189849bf4brow1_col7\" class=\"data row1 col7\" >1.000000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fcc534b7510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data and subset to ages 65+\n",
    "df = helpers.load_mimic3_example(path_to_mimic_data_folder) \n",
    "df.drop('GENDER_F', axis=1, inplace=True)\n",
    "df = df.loc[df['AGE'].ge(65),:]\n",
    "helpers.print_feature_table(df)\n",
    "display(Markdown('---'))\n",
    "\n",
    "# Generate a binary target flagging whether an observation's length_of_stay value is above or below the mean. \n",
    "mean_val=df['length_of_stay'].mean()\n",
    "df['long_los'] = df['length_of_stay'].apply(lambda x: 1 if x > mean_val else 0)\n",
    "los_tbl = df[['length_of_stay', 'long_los']].describe().transpose().round(4)\n",
    "display(los_tbl.style.applymap(helpers.highlight_col, subset=pd.IndexSlice[:, 'mean']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data and Generate Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset and Split Data\n",
    "X = df.loc[:,[c for c in df.columns if c not in ['ADMIT_ID','length_of_stay', 'long_los']]]\n",
    "y = df.loc[:, ['long_los']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model parameters (currently set as default values, but defined here to be explicit)\n",
    "rf_params = {'n_estimators': 1800, 'min_samples_split': 5, 'bootstrap': False}\n",
    "\n",
    "# Train Model\n",
    "rf_model = RandomForestClassifier(**rf_params)\n",
    "rf_model.fit(X_train, y_train.iloc[:,0])\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Random Forest Prediction Scores:\", \"\\n\", \n",
    "      classification_report(y_test, y_pred_rf, target_names=['LOS <= mean', 'LOS > mean']) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## FairLearn Models\n",
    "\n",
    "The [FairLearn](https://fairlearn.github.io/) package includes three [mitigation algorithms](https://fairlearn.github.io/user_guide/mitigation.html) designed to increase the fairness of an existing model relative to one of two user-specified fairness metrics. Both algorithms and metrics are listed in the cell below.\n",
    "\n",
    "For more information about the specifics of these fairness metrics, see also [Part 5 of the KDD Tutorial Notebook](kdd_fairness_in_healthcare_tutorial.ipynb#part5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mitigation Algorithms\n",
    "from fairlearn.reductions import GridSearch, ExponentiatedGradient\n",
    "\n",
    "# Fairness Measures\n",
    "from fairlearn.reductions import EqualizedOdds, DemographicParity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch\n",
    "\n",
    "GridSearch is a wrapper that runs a constrained optimization on a classification (or regression) model according to the fairness metric of choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GridSearch\n",
    "gs_rfEO_model = GridSearch(RandomForestClassifier(**rf_params),\n",
    "                           constraints=EqualizedOdds(),\n",
    "                           grid_size=50)\n",
    "\n",
    "gs_rfEO_model.fit(X_train, y_train, sensitive_features=X_train['LANGUAGE_ENGL'])\n",
    "y_pred_gs_rfEO = gs_rfEO_model.predict(X_test)\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      classification_report(y_test, y_pred_gs_rfEO, target_names=['LOS <= mean', 'LOS > mean']) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GridSearch\n",
    "gs_rfDP_model = GridSearch(RandomForestClassifier(**rf_params),\n",
    "                           constraints=DemographicParity(),\n",
    "                           grid_size=50)\n",
    "\n",
    "gs_rfDP_model.fit(X_train, y_train, sensitive_features=X_train['LANGUAGE_ENGL'])\n",
    "y_pred_gs_rfDP = gs_rfDP_model.predict(X_test)\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      classification_report(y_test, y_pred_gs_rfDP, target_names=['LOS <= mean', 'LOS > mean']) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExponentiatedGradient\n",
    "\n",
    "ExponentiatedGradient is another wrapper that runs a constrained optimization on a classification (or regression) model according to the fairness metric of choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eg_rfEO_model = ExponentiatedGradient(RandomForestClassifier(**rf_params), \n",
    "                                    constraints=EqualizedOdds())  #NOTE: this may alter the model; TODO: test to determine if this is true\n",
    "eg_rfEO_model.fit(X_train, y_train, sensitive_features=X_train['LANGUAGE_ENGL'])\n",
    "y_pred_eg_rfEO = eg_rfEO_model.predict(X_test)\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      classification_report(y_test, y_pred_eg_rfEO, target_names=['LOS <= mean', 'LOS > mean']) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)  # set seed for consistent results with ExponentiatedGradient\n",
    "eg_rfDP_model = ExponentiatedGradient(RandomForestClassifier(**rf_params), \n",
    "                                    constraints=DemographicParity())  #NOTE: this may alter the model; TODO: test to determine if this is true\n",
    "eg_rfDP_model.fit(X_train, y_train, sensitive_features=X_train['LANGUAGE_ENGL'])\n",
    "y_pred_eg_rfDP = eg_rfDP_model.predict(X_test)\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      classification_report(y_test, y_pred_eg_rfDP, target_names=['LOS <= mean', 'LOS > mean']) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Model Comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the Required Variables  \n",
    "\n",
    "* X (numpy array or similar pandas object): test data to be passed to the models to generate predictions. It's recommended that these be separate data from those used to train the model.\n",
    "\n",
    "* y (numpy array or similar pandas object): target data array corresponding to X. It is recommended that the target is not present in the test_data.\n",
    "\n",
    "* models (list or dict-like): the set of trained models to be evaluated. Note that the dictionary keys are assumed as model names. If a list-like object is passed, the function will set model names relative to their index (i.e. \"model_0\", \"model_1\", etc.)\n",
    "\n",
    "* protected_attr (numpy array or similar pandas object): protected attributes correspoinding to X, optionally also included in X. Note that values must currently be binary- or boolean-type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_test\n",
    "y = y_test\n",
    "protected_attr = X_test['LANGUAGE_ENGL']\n",
    "models ={'rf_model':rf_model, 'gs_rfEO_model':gs_rfEO_model, 'gs_rfDP_model':gs_rfDP_model, 'eg_rfEO_model':eg_rfEO_model, 'eg_rfDP_model':eg_rfDP_model}\n",
    "print(\"Models available in this example:\", list(models.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison.compare_models(X, y, protected_attr, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the Optimal Measure\n",
    "\n",
    "### Types of Harms\n",
    "\n",
    "### \n",
    "\n",
    "### Impossibility Theorem of Fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Alternative Comparison Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.widget import FairlearnDashboard\n",
    "\n",
    "FairlearnDashboard(sensitive_features=protected_attr.to_list(), \n",
    "                   sensitive_feature_names=['LANGUAGE_ENGL'],\n",
    "                   y_true=y.iloc[:,0].to_list(),\n",
    "                   y_pred={'rf_model':list(y_pred_rf), 'gs_rfEO_model':list(y_pred_gs_rfEO), 'gs_rfDP_model':list(y_pred_gs_rfDP), 'eg_rfEO_model':list(y_pred_eg_rfEO), 'eg_rfDP_model':list(y_pred_eg_rfDP)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
