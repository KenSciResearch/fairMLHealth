{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the Models Used in the Binary Classification Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Overview and Setup\n",
    "\n",
    "This is an example of how someone might generate and store models that can be compared for fairness. \n",
    "\n",
    "## Notebook Contents\n",
    "\n",
    "[Part 1](#part1) - Data and Analysis\n",
    "\n",
    "[Part 2](#part2) - Length of Stay Models \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[Part 2.1](#part2.1) - Out-of-the-Box Models\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[Part 2.2](#part2.2) - AIF360 Fairness-Aware  (In-Process) Models\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[Part 2.3](#part2.3) - FairLearn Fairness-Aware  (In-Process) Models\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[Part 2.4](#part2.4) - Other Methods\n",
    "\n",
    "[Part 3](#part3) - Comparing Models\n",
    "    Includes the fairMLHealth model comparison tool, as well as an example of the FairLearn Dashboard.\n",
    "\n",
    "[Part 4](#part4) - Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from fairMLHealth.tools import helpers, model_comparison as fhmc\n",
    "from fairlearn.metrics import demographic_parity_difference, demographic_parity_ratio, equalized_odds_difference, equalized_odds_ratio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "#warnings.filterwarnings('ignore', module='numpy' )\n",
    "warnings.filterwarnings('ignore', module='tensorflow' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0:00:00.000055 (hr:mn:sc)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "def check_timer(start_time=None):\n",
    "    if start_time is not None:\n",
    "        elapsed_time = datetime.datetime.now() - start_time\n",
    "        rprt = f\"{elapsed_time} (hr:mn:sc)\"\n",
    "        return rprt\n",
    "        return elapsed_time\n",
    "    else:\n",
    "        return datetime.datetime.now()\n",
    "\n",
    "start_time = check_timer()\n",
    "check_timer(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christineallen/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/christineallen/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/christineallen/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/christineallen/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/christineallen/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/christineallen/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "def aif_dataset_measures(dataset, models):\n",
    "    \"\"\" Returns a dataframe containing fairness measures for regression \n",
    "            models based on the AIF360 library\n",
    "        Note: function is based heavily on test_thresholds function from\n",
    "            the AIF360 tutorial\n",
    "    \n",
    "    \"\"\"\n",
    "    if not isinstance(models, (list, dict)):\n",
    "        models = [models]\n",
    "    if not isinstance(models, dict):\n",
    "        models = {f'model_{i}':m for i,m in enumerate(models)}\n",
    "    \n",
    "    #\n",
    "    sens_ind = 0\n",
    "    sens_attr = dataset.protected_attribute_names[sens_ind]\n",
    "    unprivileged_groups = [{sens_attr: v} for v in\n",
    "                       dataset.unprivileged_protected_attributes[sens_ind]]\n",
    "    privileged_groups = [{sens_attr: v} for v in\n",
    "                     dataset.privileged_protected_attributes[sens_ind]]\n",
    "    #\n",
    "    metric_dict = defaultdict(list)\n",
    "    for name,model in models.items():\n",
    "        y_pred = model.predict(dataset).labels\n",
    "        dataset_pred = dataset.copy()\n",
    "        dataset_pred.labels = y_pred\n",
    "        metric = ClassificationMetric(\n",
    "                    dataset, dataset_pred,\n",
    "                    unprivileged_groups=unprivileged_groups,\n",
    "                    privileged_groups=privileged_groups)\n",
    "        \n",
    "        metric_dict['Disparate Impact Ratio'].append(metric.disparate_impact())\n",
    "        metric_dict['Statistical Parity Difference'].append(metric.statistical_parity_difference())\n",
    "        metric_dict['Average Odds Difference'].append(metric.average_odds_difference())\n",
    "        metric_dict['Equal Opportunity Difference'].append(metric.equal_opportunity_difference())\n",
    "        metric_dict['Balanced Accuracy Difference'].append((metric.true_positive_rate()\n",
    "                                     + metric.true_negative_rate()) / 2)\n",
    "        metric_dict['Between-Group Coefficient of Variation'].append(metric.between_group_coefficient_of_variation())\n",
    "        metric_dict['Theil Index'].append(metric.theil_index())\n",
    "    \n",
    "    results = pd.DataFrame().from_dict(metric_dict).transpose()\n",
    "    results.columns = models.keys()\n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "----\n",
    "# Part 1 - Data and Analysis <a class=\"anchor\" id=\"part1\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading MIMIC III Data\n",
    "\n",
    "This example uses a data subset from the [MIMIC-III clinical database](https://mimic.physionet.org/gettingstarted/access/) to predict \"length of stay\" (LOS) value. For this example, LOS is total ICU time for a given hospital admission in patients 65 and above. The raw LOS value is then converted to a binary value specifying whether an admission's length of stay is greater than the sample mean. A baseline model is then generated using the Scikit-Learn RandomForestClassifier.\n",
    "\n",
    "Note that the code below will automatically unzip and format all necessary data for these experiments from a raw download of MIMIC-III data (saving the formatted data in the same MIMIC folder). MIMIC-III is a freely available database, however all users must pass a quick human subjects certification course. If you would like to run this example on your own, [follow these steps to be granted access to MIMIC III](https://mimic.physionet.org/gettingstarted/access/) and download the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# path_to_mimic_data_folder = \"[path to your downloaded data folder]\"\n",
    "path_to_mimic_data_folder = \"~/data/MIMIC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output file for combined data and models\n",
    "output_file = os.path.expanduser(\"~/data/fairness_and_bias/mimic_model_comparison/binary_classification.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data Subset <a id=\"datasubset\"></a>\n",
    "\n",
    "Example models in this notebook use data from all years of the MIMIC-III dataset for patients aged 65 and older. Data are imported at the encounter level with all additional patient identification dropped. All models include an \"AGE\" feature, simplified to 5-year bins, as well as boolean diagnosis and procedure features categorized through the Clinical Classifications Software system ([HCUP](https://www.hcup-us.ahrq.gov/toolssoftware/ccs/ccs.jsp)). All features other than age are one-hot encoded and prefixed with their variable type (e.g. \"GENDER_\", \"ETHNICITY_\").  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " This data subset has 22434 total observations and 648 input features \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw Feature</th>\n",
       "      <th>Category Count (Encoded Features)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DIAGNOSIS</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ETHNICITY</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GENDER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INSURANCE</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LANGUAGE</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MARRIED</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PROCEDURE</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RELIGION</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Raw Feature  Category Count (Encoded Features)\n",
       "0         AGE                                  1\n",
       "1   DIAGNOSIS                                282\n",
       "2   ETHNICITY                                 41\n",
       "3      GENDER                                  1\n",
       "4   INSURANCE                                  5\n",
       "5    LANGUAGE                                 69\n",
       "6     MARRIED                                  7\n",
       "7   PROCEDURE                                222\n",
       "8    RELIGION                                 20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADMIT_ID</th>\n",
       "      <th>AGE</th>\n",
       "      <th>GENDER_M</th>\n",
       "      <th>ETHNICITY_AMERICAN INDIAN/ALASKA NATIVE</th>\n",
       "      <th>ETHNICITY_AMERICAN INDIAN/ALASKA NATIVE FEDERALLY RECOGNIZED TRIBE</th>\n",
       "      <th>ETHNICITY_ASIAN</th>\n",
       "      <th>ETHNICITY_ASIAN - ASIAN INDIAN</th>\n",
       "      <th>ETHNICITY_ASIAN - CAMBODIAN</th>\n",
       "      <th>ETHNICITY_ASIAN - CHINESE</th>\n",
       "      <th>ETHNICITY_ASIAN - FILIPINO</th>\n",
       "      <th>...</th>\n",
       "      <th>PROCEDURE_CCS_222</th>\n",
       "      <th>PROCEDURE_CCS_223</th>\n",
       "      <th>PROCEDURE_CCS_224</th>\n",
       "      <th>PROCEDURE_CCS_225</th>\n",
       "      <th>PROCEDURE_CCS_226</th>\n",
       "      <th>PROCEDURE_CCS_227</th>\n",
       "      <th>PROCEDURE_CCS_228</th>\n",
       "      <th>PROCEDURE_CCS_229</th>\n",
       "      <th>PROCEDURE_CCS_231</th>\n",
       "      <th>length_of_stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>357648</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.144444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>344556</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.496528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316654</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.768056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>389994</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.988889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>354902</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.364583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 650 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ADMIT_ID   AGE  GENDER_M  ETHNICITY_AMERICAN INDIAN/ALASKA NATIVE  \\\n",
       "0    357648  65.0         0                                        0   \n",
       "1    344556  70.0         1                                        0   \n",
       "2    316654  75.0         1                                        0   \n",
       "5    389994  70.0         1                                        0   \n",
       "7    354902  75.0         1                                        0   \n",
       "\n",
       "   ETHNICITY_AMERICAN INDIAN/ALASKA NATIVE FEDERALLY RECOGNIZED TRIBE  \\\n",
       "0                                                  0                    \n",
       "1                                                  0                    \n",
       "2                                                  0                    \n",
       "5                                                  0                    \n",
       "7                                                  0                    \n",
       "\n",
       "   ETHNICITY_ASIAN  ETHNICITY_ASIAN - ASIAN INDIAN  \\\n",
       "0                0                               0   \n",
       "1                0                               0   \n",
       "2                0                               0   \n",
       "5                0                               0   \n",
       "7                0                               0   \n",
       "\n",
       "   ETHNICITY_ASIAN - CAMBODIAN  ETHNICITY_ASIAN - CHINESE  \\\n",
       "0                            0                          0   \n",
       "1                            0                          0   \n",
       "2                            0                          0   \n",
       "5                            0                          0   \n",
       "7                            0                          0   \n",
       "\n",
       "   ETHNICITY_ASIAN - FILIPINO  ...  PROCEDURE_CCS_222  PROCEDURE_CCS_223  \\\n",
       "0                           0  ...                  0                  0   \n",
       "1                           0  ...                  1                  0   \n",
       "2                           0  ...                  0                  0   \n",
       "5                           0  ...                  0                  0   \n",
       "7                           0  ...                  1                  0   \n",
       "\n",
       "   PROCEDURE_CCS_224  PROCEDURE_CCS_225  PROCEDURE_CCS_226  PROCEDURE_CCS_227  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  0                  0                  0                  0   \n",
       "5                  0                  0                  0                  1   \n",
       "7                  0                  0                  0                  1   \n",
       "\n",
       "   PROCEDURE_CCS_228  PROCEDURE_CCS_229  PROCEDURE_CCS_231  length_of_stay  \n",
       "0                  0                  0                  0        1.144444  \n",
       "1                  0                  0                  0        5.496528  \n",
       "2                  0                  0                  0        6.768056  \n",
       "5                  0                  0                  0        6.988889  \n",
       "7                  0                  0                  0        5.364583  \n",
       "\n",
       "[5 rows x 650 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = helpers.load_mimic3_example(path_to_mimic_data_folder) \n",
    "df.drop('GENDER_F', axis=1, inplace=True)\n",
    "df = df.loc[df['AGE'].ge(65),:]\n",
    "helpers.print_feature_table(df)\n",
    "display(Markdown('---'))\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_094b85f2_04e2_11eb_bd5f_f0189849bf4brow0_col1,#T_094b85f2_04e2_11eb_bd5f_f0189849bf4brow1_col1{\n",
       "            background-color:  aquamarine;\n",
       "        }</style><table id=\"T_094b85f2_04e2_11eb_bd5f_f0189849bf4b\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >count</th>        <th class=\"col_heading level0 col1\" >mean</th>        <th class=\"col_heading level0 col2\" >std</th>        <th class=\"col_heading level0 col3\" >min</th>        <th class=\"col_heading level0 col4\" >25%</th>        <th class=\"col_heading level0 col5\" >50%</th>        <th class=\"col_heading level0 col6\" >75%</th>        <th class=\"col_heading level0 col7\" >max</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_094b85f2_04e2_11eb_bd5f_f0189849bf4blevel0_row0\" class=\"row_heading level0 row0\" >length_of_stay</th>\n",
       "                        <td id=\"T_094b85f2_04e2_11eb_bd5f_f0189849bf4brow0_col0\" class=\"data row0 col0\" >22434.000000</td>\n",
       "                        <td id=\"T_094b85f2_04e2_11eb_bd5f_f0189849bf4brow0_col1\" class=\"data row0 col1\" >9.115200</td>\n",
       "                        <td id=\"T_094b85f2_04e2_11eb_bd5f_f0189849bf4brow0_col2\" class=\"data row0 col2\" >6.208700</td>\n",
       "                        <td id=\"T_094b85f2_04e2_11eb_bd5f_f0189849bf4brow0_col3\" class=\"data row0 col3\" >0.004200</td>\n",
       "                        <td id=\"T_094b85f2_04e2_11eb_bd5f_f0189849bf4brow0_col4\" class=\"data row0 col4\" >4.735200</td>\n",
       "                        <td id=\"T_094b85f2_04e2_11eb_bd5f_f0189849bf4brow0_col5\" class=\"data row0 col5\" >7.579900</td>\n",
       "                        <td id=\"T_094b85f2_04e2_11eb_bd5f_f0189849bf4brow0_col6\" class=\"data row0 col6\" >12.017700</td>\n",
       "                        <td id=\"T_094b85f2_04e2_11eb_bd5f_f0189849bf4brow0_col7\" class=\"data row0 col7\" >29.988900</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_094b85f2_04e2_11eb_bd5f_f0189849bf4blevel0_row1\" class=\"row_heading level0 row1\" >long_los</th>\n",
       "                        <td id=\"T_094b85f2_04e2_11eb_bd5f_f0189849bf4brow1_col0\" class=\"data row1 col0\" >22434.000000</td>\n",
       "                        <td id=\"T_094b85f2_04e2_11eb_bd5f_f0189849bf4brow1_col1\" class=\"data row1 col1\" >0.388000</td>\n",
       "                        <td id=\"T_094b85f2_04e2_11eb_bd5f_f0189849bf4brow1_col2\" class=\"data row1 col2\" >0.487300</td>\n",
       "                        <td id=\"T_094b85f2_04e2_11eb_bd5f_f0189849bf4brow1_col3\" class=\"data row1 col3\" >0.000000</td>\n",
       "                        <td id=\"T_094b85f2_04e2_11eb_bd5f_f0189849bf4brow1_col4\" class=\"data row1 col4\" >0.000000</td>\n",
       "                        <td id=\"T_094b85f2_04e2_11eb_bd5f_f0189849bf4brow1_col5\" class=\"data row1 col5\" >0.000000</td>\n",
       "                        <td id=\"T_094b85f2_04e2_11eb_bd5f_f0189849bf4brow1_col6\" class=\"data row1 col6\" >1.000000</td>\n",
       "                        <td id=\"T_094b85f2_04e2_11eb_bd5f_f0189849bf4brow1_col7\" class=\"data row1 col7\" >1.000000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd35e7b9b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate a binary target flagging whether an observation's length_of_stay value is above or below the mean. \n",
    "mean_val=df['length_of_stay'].mean()\n",
    "df['long_los'] = df['length_of_stay'].apply(lambda x: 1 if x > mean_val else 0)\n",
    "los_tbl = df[['length_of_stay', 'long_los']].describe().transpose().round(4)\n",
    "display(los_tbl.style.applymap(helpers.highlight_col, subset=pd.IndexSlice[:, 'mean']))\n",
    "\n",
    "# Display LOS distributions\n",
    "display(Markdown('---'))\n",
    "ax = df['length_of_stay'].plot(kind='kde', title=\"Probability Density of Length of Stay\")\n",
    "ax.set_xlabel(\"Length of Stay in Days\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "----\n",
    "# Part 2 - Length of Stay Models <a class=\"anchor\" id=\"part2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as sk_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "np.random.seed(36)  # set seed for consistent results with ExponentiatedGradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset and Split Data\n",
    "X = df.loc[:,[c for c in df.columns if c not in ['ADMIT_ID','length_of_stay', 'long_los']]]\n",
    "y = df.loc[:, ['long_los']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline - Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Prediction Scores for Random Sampling: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  LOS > mean       0.61      0.61      0.61     13730\n",
      " LOS <= mean       0.39      0.38      0.39      8704\n",
      "\n",
      "    accuracy                           0.52     22434\n",
      "   macro avg       0.50      0.50      0.50     22434\n",
      "weighted avg       0.52      0.52      0.52     22434\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate \"predictions\" as random sample of target values\n",
    "y = df['long_los']\n",
    "pos_weight = y.mean()\n",
    "weights = [1-pos_weight, pos_weight]\n",
    "values = list(set(y))\n",
    "y_pred_baseline = np.array(random.choices(values, weights, k=df.shape[0]))\n",
    "y_prob_baseline = y_pred_baseline\n",
    "\n",
    "# display baseline performance \n",
    "print(\"\\n\", \"Prediction Scores for Random Sampling:\", \"\\n\", \n",
    "      sk_metric.classification_report(y, y_pred_baseline, target_names=['LOS > mean', 'LOS <= mean']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Part 2.1 - Out-of-the-Box Models <a class=\"anchor\" id=\"part2.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15030, 648) (15030, 1) (7404, 648) (7404, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 0:00:00.332273 (hr:mn:sc)\n",
      "\n",
      " Naive Bayes Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " LOS <= mean       0.76      0.85      0.80      4531\n",
      "  LOS > mean       0.71      0.58      0.64      2873\n",
      "\n",
      "    accuracy                           0.75      7404\n",
      "   macro avg       0.74      0.72      0.72      7404\n",
      "weighted avg       0.74      0.75      0.74      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_params = {'alpha':20, 'fit_prior':True}\n",
    "\n",
    "# Train Model\n",
    "start_time = check_timer()\n",
    "nb_model = BernoulliNB(**nb_params)\n",
    "nb_model.fit(X_train, y_train.iloc[:,0])\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "print(\"Model finished in\", check_timer(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Naive Bayes Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_nb, target_names=['LOS <= mean', 'LOS > mean']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 0:00:00.656993 (hr:mn:sc)\n",
      "\n",
      " Decision Tree Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " LOS <= mean       0.73      0.85      0.79      4531\n",
      "  LOS > mean       0.69      0.52      0.59      2873\n",
      "\n",
      "    accuracy                           0.72      7404\n",
      "   macro avg       0.71      0.68      0.69      7404\n",
      "weighted avg       0.72      0.72      0.71      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_params = {'min_samples_split': 10,\n",
    " 'min_samples_leaf': 2,\n",
    " 'max_depth': 10,\n",
    " 'criterion': 'entropy'}\n",
    "\n",
    "# Train Model\n",
    "start_time = check_timer()\n",
    "dt_model = DecisionTreeClassifier(**dt_params)\n",
    "dt_model.fit(X_train, y_train.iloc[:,0])\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "print(\"Model finished in\", check_timer(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Decision Tree Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_dt, target_names=['LOS <= mean', 'LOS > mean']) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 0:03:46.567929 (hr:mn:sc)\n",
      "\n",
      " Random Forest Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " LOS <= mean       0.77      0.90      0.83      4531\n",
      "  LOS > mean       0.78      0.57      0.66      2873\n",
      "\n",
      "    accuracy                           0.77      7404\n",
      "   macro avg       0.77      0.73      0.74      7404\n",
      "weighted avg       0.77      0.77      0.76      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_params = {'criterion':'entropy', 'n_estimators': 1800, 'min_samples_split': 5, 'bootstrap': False}\n",
    "\n",
    "# Train Model\n",
    "start_time = check_timer()\n",
    "rf_model = RandomForestClassifier(**rf_params)\n",
    "rf_model.fit(X_train, y_train.iloc[:,0])\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(\"Model finished in\", check_timer(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Random Forest Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_rf, target_names=['LOS <= mean', 'LOS > mean']) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logit Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 0:00:41.919341 (hr:mn:sc)\n",
      "\n",
      " Logit Regression Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " LOS <= mean       0.79      0.87      0.83      4531\n",
      "  LOS > mean       0.75      0.63      0.69      2873\n",
      "\n",
      "    accuracy                           0.78      7404\n",
      "   macro avg       0.77      0.75      0.76      7404\n",
      "weighted avg       0.77      0.78      0.77      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_params = {'penalty':\"none\", 'max_iter':10**4}\n",
    "\n",
    "# Train Model\n",
    "start_time = check_timer()\n",
    "lr_model = LogisticRegression(**lr_params)\n",
    "lr_model.fit(X_train, y_train.iloc[:,0])\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "print(\"Model finished in\", check_timer(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Logit Regression Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_lr, zero_division=0, target_names=['LOS <= mean', 'LOS > mean']) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', message=\"Liblinear failed to converge, increase the number of iterations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 0:00:29.011797 (hr:mn:sc)\n",
      "\n",
      " SVM Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " LOS <= mean       0.74      0.94      0.83      4531\n",
      "  LOS > mean       0.84      0.49      0.62      2873\n",
      "\n",
      "    accuracy                           0.77      7404\n",
      "   macro avg       0.79      0.72      0.73      7404\n",
      "weighted avg       0.78      0.77      0.75      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_params = {'max_iter':10**4}\n",
    "\n",
    "# Train Model\n",
    "start_time = check_timer()\n",
    "svm_model = LinearSVC(**svm_params)\n",
    "svm_model.fit(X_train, y_train.iloc[:,0])\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "print(\"Model finished in\", check_timer(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"SVM Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_svm, target_names=['LOS <= mean', 'LOS > mean'], zero_division=0) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 0:00:00.620028 (hr:mn:sc)\n",
      "\n",
      " Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " LOS <= mean       0.73      0.91      0.81      4531\n",
      "  LOS > mean       0.76      0.47      0.58      2873\n",
      "\n",
      "    accuracy                           0.74      7404\n",
      "   macro avg       0.74      0.69      0.69      7404\n",
      "weighted avg       0.74      0.74      0.72      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {'objective':'binary', 'metric':'auc', 'learning_rate':0.03,\n",
    "              'num_leaves':10, 'max_depth':3}\n",
    "\n",
    "start_time = check_timer()\n",
    "lgb_model = lgb.LGBMClassifier(**lgb_params)\n",
    "lgb_model.fit(X_train, y_train.iloc[:,0])\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "print(\"Model finished in\", check_timer(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_lgb, target_names=['LOS <= mean', 'LOS > mean']) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 0:01:49.837946 (hr:mn:sc)\n",
      "\n",
      " Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " LOS <= mean       0.79      0.88      0.83      4531\n",
      "  LOS > mean       0.77      0.63      0.70      2873\n",
      "\n",
      "    accuracy                           0.78      7404\n",
      "   macro avg       0.78      0.76      0.76      7404\n",
      "weighted avg       0.78      0.78      0.78      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {'colsample_bytree': 1.0, 'gamma': 2, 'learning_rate': 0.05, 'max_depth': 5, \n",
    "                'min_child_weight': 1,  'n_estimators': 600, 'subsample': 0.6}\n",
    "\n",
    "# Train Model\n",
    "xgb_model = XGBClassifier(**xgb_params)\n",
    "start_time = check_timer()\n",
    "xgb_model.fit(X_train, y_train.iloc[:,0])\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "print(\"Model finished in\", check_timer(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_xgb, target_names=['LOS <= mean', 'LOS > mean']) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Part 2.2 - AIF360 Fairness-Aware  (In-Process) Models <a class=\"anchor\" id=\"part2.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "The AIF360 fairness-aware solutions require data to be in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aif360.datasets as aifdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>GENDER_M</th>\n",
       "      <th>ETHNICITY_AMERICAN INDIAN/ALASKA NATIVE</th>\n",
       "      <th>ETHNICITY_AMERICAN INDIAN/ALASKA NATIVE FEDERALLY RECOGNIZED TRIBE</th>\n",
       "      <th>ETHNICITY_ASIAN</th>\n",
       "      <th>ETHNICITY_ASIAN - ASIAN INDIAN</th>\n",
       "      <th>ETHNICITY_ASIAN - CAMBODIAN</th>\n",
       "      <th>ETHNICITY_ASIAN - CHINESE</th>\n",
       "      <th>ETHNICITY_ASIAN - FILIPINO</th>\n",
       "      <th>ETHNICITY_ASIAN - JAPANESE</th>\n",
       "      <th>...</th>\n",
       "      <th>PROCEDURE_CCS_222</th>\n",
       "      <th>PROCEDURE_CCS_223</th>\n",
       "      <th>PROCEDURE_CCS_224</th>\n",
       "      <th>PROCEDURE_CCS_225</th>\n",
       "      <th>PROCEDURE_CCS_226</th>\n",
       "      <th>PROCEDURE_CCS_227</th>\n",
       "      <th>PROCEDURE_CCS_228</th>\n",
       "      <th>PROCEDURE_CCS_229</th>\n",
       "      <th>PROCEDURE_CCS_231</th>\n",
       "      <th>long_los</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 649 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AGE  GENDER_M  ETHNICITY_AMERICAN INDIAN/ALASKA NATIVE  \\\n",
       "0  80.0         1                                        0   \n",
       "1  80.0         1                                        0   \n",
       "2  80.0         0                                        0   \n",
       "3  65.0         0                                        0   \n",
       "4  75.0         1                                        0   \n",
       "\n",
       "   ETHNICITY_AMERICAN INDIAN/ALASKA NATIVE FEDERALLY RECOGNIZED TRIBE  \\\n",
       "0                                                  0                    \n",
       "1                                                  0                    \n",
       "2                                                  0                    \n",
       "3                                                  0                    \n",
       "4                                                  0                    \n",
       "\n",
       "   ETHNICITY_ASIAN  ETHNICITY_ASIAN - ASIAN INDIAN  \\\n",
       "0                0                               0   \n",
       "1                0                               0   \n",
       "2                0                               0   \n",
       "3                0                               0   \n",
       "4                0                               0   \n",
       "\n",
       "   ETHNICITY_ASIAN - CAMBODIAN  ETHNICITY_ASIAN - CHINESE  \\\n",
       "0                            0                          0   \n",
       "1                            0                          0   \n",
       "2                            0                          0   \n",
       "3                            0                          0   \n",
       "4                            0                          0   \n",
       "\n",
       "   ETHNICITY_ASIAN - FILIPINO  ETHNICITY_ASIAN - JAPANESE  ...  \\\n",
       "0                           0                           0  ...   \n",
       "1                           0                           0  ...   \n",
       "2                           0                           0  ...   \n",
       "3                           0                           0  ...   \n",
       "4                           0                           0  ...   \n",
       "\n",
       "   PROCEDURE_CCS_222  PROCEDURE_CCS_223  PROCEDURE_CCS_224  PROCEDURE_CCS_225  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  1                  0                  0                  0   \n",
       "3                  0                  0                  0                  0   \n",
       "4                  0                  0                  0                  0   \n",
       "\n",
       "   PROCEDURE_CCS_226  PROCEDURE_CCS_227  PROCEDURE_CCS_228  PROCEDURE_CCS_229  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  0                  0                  0                  0   \n",
       "3                  0                  0                  0                  0   \n",
       "4                  0                  0                  0                  0   \n",
       "\n",
       "   PROCEDURE_CCS_231  long_los  \n",
       "0                  0         0  \n",
       "1                  0         0  \n",
       "2                  0         1  \n",
       "3                  1         0  \n",
       "4                  0         1  \n",
       "\n",
       "[5 rows x 649 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "df = pd.concat([test_data, train_data], ignore_index=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aif_data = pd.concat([X, y], axis=1)\n",
    "los_dataset = aifdata.StandardDataset(df=aif_data, \n",
    "                        label_name='long_los',\n",
    "                        favorable_classes=[1],\n",
    "                        instance_weights_name=None,\n",
    "                        categorical_features=['AGE'],\n",
    "                        protected_attribute_names=['LANGUAGE_ENGL'],       \n",
    "                        privileged_classes=[[1]],                   \n",
    "                        custom_preprocessing=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GerryFair Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.algorithms.inprocessing import GerryFairClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1, error: 0.20986003387715074, fairness violation: 0.0036408985147281703, violated group size: 0.1964428991709013\n",
      "iteration: 2, error: 0.20986003387715074, fairness violation: 0.0036408985147281703, violated group size: 0.1964428991709013\n",
      "iteration: 3, error: 0.20986003387715074, fairness violation: 0.0036408985147281703, violated group size: 0.1964428991709013\n",
      "iteration: 4, error: 0.20986003387715074, fairness violation: 0.0036408985147281703, violated group size: 0.1964428991709013\n",
      "iteration: 5, error: 0.20986003387715074, fairness violation: 0.0036408985147281703, violated group size: 0.1964428991709013\n",
      "Model finished in 0:00:11.935275 (hr:mn:sc)\n",
      "\n",
      " Note: Theoretically a predictor can be set, but no valid argument could be found during testing. Per the documentation: \"predictor: Hypothesis class for the Learner. Supports LR, SVM, KR, Trees\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "C = 100\n",
    "print_flag = True\n",
    "gamma = .005\n",
    "\n",
    "\n",
    "aif_gf_model = GerryFairClassifier(fairness_def='FN', #fairness_def: Fairness notion, FP, FN\n",
    "                                   C=C, \n",
    "                                   printflag=print_flag, \n",
    "                                   gamma=gamma, \n",
    "                                   max_iters=500, \n",
    "                                   heatmapflag=False)\n",
    "\n",
    "start_time = check_timer()\n",
    "aif_gf_model.fit(los_dataset, early_termination=True)\n",
    "yhat_aifgf = aif_gf_model.predict(los_dataset, threshold=False)\n",
    "print(\"Model finished in\", check_timer(start_time))\n",
    "\n",
    "print(\"\\n\",\n",
    "      \"Note: Theoretically a predictor can be set, but no valid argument could be found during testing.\",\n",
    "      \"Per the documentation: \\\"predictor: Hypothesis class for the Learner. Supports LR, SVM, KR, Trees\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prejudice Remover Regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.algorithms.inprocessing import prejudice_remover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 0:01:32.011137 (hr:mn:sc)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "aif_prr_model = prejudice_remover.PrejudiceRemover(sensitive_attr='LANGUAGE_ENGL')\n",
    "start_time = check_timer()\n",
    "aif_prr_model.fit(los_dataset)\n",
    "yhat_aif_prr = aif_prr_model.predict(los_dataset)\n",
    "print(\"Model finished in\", check_timer(start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial Debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.algorithms.inprocessing import adversarial_debiasing\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/christineallen/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:137: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/christineallen/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:141: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/christineallen/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:84: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /Users/christineallen/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:89: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/christineallen/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/christineallen/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:159: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/christineallen/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:161: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/christineallen/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:165: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/christineallen/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:187: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "epoch 0; iter: 0; batch classifier loss: 0.747727\n",
      "epoch 1; iter: 0; batch classifier loss: 0.475418\n",
      "epoch 2; iter: 0; batch classifier loss: 0.542145\n",
      "epoch 3; iter: 0; batch classifier loss: 0.393214\n",
      "epoch 4; iter: 0; batch classifier loss: 0.392552\n",
      "epoch 5; iter: 0; batch classifier loss: 0.339938\n",
      "epoch 6; iter: 0; batch classifier loss: 0.306431\n",
      "epoch 7; iter: 0; batch classifier loss: 0.361059\n",
      "epoch 8; iter: 0; batch classifier loss: 0.315370\n",
      "epoch 9; iter: 0; batch classifier loss: 0.311666\n",
      "epoch 10; iter: 0; batch classifier loss: 0.259920\n",
      "epoch 11; iter: 0; batch classifier loss: 0.321432\n",
      "epoch 12; iter: 0; batch classifier loss: 0.245377\n",
      "epoch 13; iter: 0; batch classifier loss: 0.253675\n",
      "epoch 14; iter: 0; batch classifier loss: 0.251444\n",
      "epoch 15; iter: 0; batch classifier loss: 0.197511\n",
      "epoch 16; iter: 0; batch classifier loss: 0.214764\n",
      "epoch 17; iter: 0; batch classifier loss: 0.198867\n",
      "epoch 18; iter: 0; batch classifier loss: 0.197046\n",
      "epoch 19; iter: 0; batch classifier loss: 0.213651\n",
      "epoch 20; iter: 0; batch classifier loss: 0.132546\n",
      "epoch 21; iter: 0; batch classifier loss: 0.117145\n",
      "epoch 22; iter: 0; batch classifier loss: 0.174650\n",
      "epoch 23; iter: 0; batch classifier loss: 0.143935\n",
      "epoch 24; iter: 0; batch classifier loss: 0.160821\n",
      "epoch 25; iter: 0; batch classifier loss: 0.146002\n",
      "epoch 26; iter: 0; batch classifier loss: 0.139341\n",
      "epoch 27; iter: 0; batch classifier loss: 0.105374\n",
      "epoch 28; iter: 0; batch classifier loss: 0.085729\n",
      "epoch 29; iter: 0; batch classifier loss: 0.101847\n",
      "epoch 30; iter: 0; batch classifier loss: 0.149267\n",
      "epoch 31; iter: 0; batch classifier loss: 0.080899\n",
      "epoch 32; iter: 0; batch classifier loss: 0.095757\n",
      "epoch 33; iter: 0; batch classifier loss: 0.165367\n",
      "epoch 34; iter: 0; batch classifier loss: 0.108734\n",
      "epoch 35; iter: 0; batch classifier loss: 0.128933\n",
      "epoch 36; iter: 0; batch classifier loss: 0.097160\n",
      "epoch 37; iter: 0; batch classifier loss: 0.089976\n",
      "epoch 38; iter: 0; batch classifier loss: 0.108360\n",
      "epoch 39; iter: 0; batch classifier loss: 0.129311\n",
      "epoch 40; iter: 0; batch classifier loss: 0.086017\n",
      "epoch 41; iter: 0; batch classifier loss: 0.063416\n",
      "epoch 42; iter: 0; batch classifier loss: 0.058515\n",
      "epoch 43; iter: 0; batch classifier loss: 0.112771\n",
      "epoch 44; iter: 0; batch classifier loss: 0.058491\n",
      "epoch 45; iter: 0; batch classifier loss: 0.102717\n",
      "epoch 46; iter: 0; batch classifier loss: 0.075679\n",
      "epoch 47; iter: 0; batch classifier loss: 0.085723\n",
      "epoch 48; iter: 0; batch classifier loss: 0.080337\n",
      "epoch 49; iter: 0; batch classifier loss: 0.060604\n",
      "Model finished in 0:00:17.345917 (hr:mn:sc)\n"
     ]
    }
   ],
   "source": [
    "sess = tf.compat.v1.Session()\n",
    "\n",
    "aif_adb_model = adversarial_debiasing.AdversarialDebiasing(privileged_groups = [{'LANGUAGE_ENGL': 1}], \n",
    "                                                           unprivileged_groups = [{'LANGUAGE_ENGL': 0}],\n",
    "                                                             scope_name='plain_classifier',\n",
    "                                                          debias=False,\n",
    "                                                          sess=sess)\n",
    "start_time = check_timer()\n",
    "aif_adb_model.fit(los_dataset)\n",
    "yhat_aifadb = aif_adb_model.predict(los_dataset)\n",
    "print(\"Model finished in\", check_timer(start_time))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other AIF360 Fairness-Aware Options that are Not Yet Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.algorithms.inprocessing import meta_fair_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta_fair_classifier failed to converge in testing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "aif_mfc_model = meta_fair_classifier.MetaFairClassifier(sensitive_attr='LANGUAGE_ENGL')\n",
    "#aif_mfc_model.fit(los_dataset)\n",
    "#yhat_aifmfc = aif_mfc_model.predict(los_dataset)\n",
    "print(\"meta_fair_classifier failed to converge in testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Part 2.3 - FairLearn Fairness-Aware  (In-Process) Models <a class=\"anchor\" id=\"part2.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.reductions import GridSearch, ExponentiatedGradient\n",
    "from fairlearn.reductions import EqualizedOdds, DemographicParity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fair GridSearch with LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 0:00:49.615768 (hr:mn:sc)\n",
      "\n",
      " Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " LOS <= mean       0.73      0.91      0.81      4531\n",
      "  LOS > mean       0.76      0.47      0.58      2873\n",
      "\n",
      "    accuracy                           0.74      7404\n",
      "   macro avg       0.74      0.69      0.69      7404\n",
      "weighted avg       0.74      0.74      0.72      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train GridSearch\n",
    "gs_lgb_model = GridSearch(lgb.LGBMClassifier(**lgb_params),\n",
    "                           constraints=EqualizedOdds(),\n",
    "                           grid_size=45)\n",
    "\n",
    "start_time = check_timer()\n",
    "gs_lgb_model.fit(X_train, y_train, sensitive_features=X_train['LANGUAGE_ENGL'])\n",
    "y_pred_gs_lgb = gs_lgb_model.predict(X_test)\n",
    "print(\"Model finished in\", check_timer(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_gs_lgb, target_names=['LOS <= mean', 'LOS > mean']) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fair GridSearch  with XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Kernel Failure when running GridSearch on XGBOOST\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "# Train GridSearch\n",
    "gs_xgb_model = GridSearch(XGBClassifier(**xgb_params),\n",
    "                   constraints=EqualizedOdds(),\n",
    "                   grid_size=45)\n",
    "\n",
    "start_time = check_timer()\n",
    "gs_xgb_model.fit(X_train, y_train, sensitive_features=X_train['LANGUAGE_ENGL'])\n",
    "y_pred_gs_xgb = gs_xgb_model.predict(X_test)\n",
    "print(\"Model finished in\", check_timer(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_gs_xgb, target_names=['LOS <= mean', 'LOS > mean']) )\n",
    "'''\n",
    "print(\"Frequent Kernel Failure when running GridSearch on XGBOOST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fair GridSearch on Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 1:28:48.973636 (hr:mn:sc)\n",
      "\n",
      " Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " LOS <= mean       0.77      0.90      0.83      4531\n",
      "  LOS > mean       0.78      0.57      0.66      2873\n",
      "\n",
      "    accuracy                           0.77      7404\n",
      "   macro avg       0.77      0.73      0.74      7404\n",
      "weighted avg       0.77      0.77      0.76      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train GridSearch\n",
    "gs_rfEO_model = GridSearch(RandomForestClassifier(**rf_params),\n",
    "                   constraints=EqualizedOdds(),\n",
    "                   grid_size=45)\n",
    "\n",
    "start_time = check_timer()\n",
    "gs_rfEO_model.fit(X_train, y_train, sensitive_features=X_train['LANGUAGE_ENGL'])\n",
    "y_pred_gs_rfEO = gs_rfEO_model.predict(X_test)\n",
    "print(\"Model finished in\", check_timer(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_gs_rfEO, target_names=['LOS <= mean', 'LOS > mean']) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 1:28:26.676901 (hr:mn:sc)\n",
      "\n",
      " Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " LOS <= mean       0.75      0.89      0.81      4531\n",
      "  LOS > mean       0.76      0.52      0.62      2873\n",
      "\n",
      "    accuracy                           0.75      7404\n",
      "   macro avg       0.75      0.71      0.72      7404\n",
      "weighted avg       0.75      0.75      0.74      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train GridSearch\n",
    "gs_rfDP_model = GridSearch(RandomForestClassifier(**rf_params),\n",
    "                           constraints=DemographicParity(),\n",
    "                           grid_size=45)\n",
    "\n",
    "start_time = check_timer()\n",
    "gs_rfDP_model.fit(X_train, y_train, sensitive_features=X_train['LANGUAGE_ENGL'])\n",
    "y_pred_gs_rfDP = gs_rfDP_model.predict(X_test)\n",
    "print(\"Model finished in\", check_timer(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_gs_rfDP, target_names=['LOS <= mean', 'LOS > mean']) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponentiated Gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eg_lgb_model = ExponentiatedGradient(lgb.LGBMClassifier(**lgb_params), \n",
    "                                     constraints=DemographicParity())\n",
    "eg_lgb_model.fit(X_train, y_train, sensitive_features=X_train['LANGUAGE_ENGL'])\n",
    "y_pred_eg_lgb = eg_lgb_model.predict(X_test)\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_eg_lgb, target_names=['LOS <= mean', 'LOS > mean']) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eg_rf_model = ExponentiatedGradient(RandomForestClassifier(**rf_params), \n",
    "                                    constraints=DemographicParity())  #NOTE: this may alter the model; TODO: test to determine if this is true\n",
    "eg_rf_model.fit(X_train, y_train, sensitive_features=X_train['LANGUAGE_ENGL'])\n",
    "y_pred_eg_rf = eg_rf_model.predict(X_test)\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_eg_rf, target_names=['LOS <= mean', 'LOS > mean']) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Part 2.4 - Other Methods <a class=\"anchor\" id=\"part2.4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical Risk Minimization (Fair_ERM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear FERM\n",
    "\n",
    "Code taken from https://github.com/jmikko/fair_ERM/blob/master/linear_ferm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_FERM:\n",
    "    \"\"\" Fairness-Aware Classifier from https://github.com/jmikko/fair_ERM/blob/master/linear_ferm.py\n",
    "    \"\"\"\n",
    "    # The linear FERM algorithm\n",
    "    def __init__(self, dataset, model, sensible_feature):\n",
    "        self.dataset = dataset\n",
    "        self.values_of_sensible_feature = list(set(sensible_feature))\n",
    "        self.list_of_sensible_feature_train = sensible_feature\n",
    "        self.val0 = np.min(self.values_of_sensible_feature)\n",
    "        self.val1 = np.max(self.values_of_sensible_feature)\n",
    "        self.model = model\n",
    "        self.u = None\n",
    "        self.max_i = None\n",
    "\n",
    "    def new_representation(self, examples):\n",
    "        if self.u is None:\n",
    "            sys.exit('Model not trained yet!')\n",
    "            return 0\n",
    "\n",
    "        new_examples = np.array([ex - self.u * (ex[self.max_i] / self.u[self.max_i]) for ex in examples])\n",
    "        new_examples = np.delete(new_examples, self.max_i, 1)\n",
    "        return new_examples\n",
    "\n",
    "    def predict(self, examples):\n",
    "        new_examples = self.new_representation(examples)\n",
    "        prediction = self.model.predict(new_examples)\n",
    "        return prediction\n",
    "\n",
    "    def fit(self):\n",
    "        # Evaluation of the empirical averages among the groups\n",
    "        tmp = [ex for idx, ex in enumerate(self.dataset.data)\n",
    "               if self.dataset.target[idx] == 1 and self.list_of_sensible_feature_train[idx] == self.val1]\n",
    "        average_A_1 = np.mean(tmp, 0)\n",
    "        tmp = [ex for idx, ex in enumerate(self.dataset.data)\n",
    "               if self.dataset.target[idx] == 1 and self.list_of_sensible_feature_train[idx] == self.val0]\n",
    "        average_not_A_1 = np.mean(tmp, 0)\n",
    "\n",
    "        # Evaluation of the vector u (difference among the two averages)\n",
    "        self.u = -(average_A_1 - average_not_A_1)\n",
    "        self.max_i = np.argmax(self.u)\n",
    "\n",
    "        # Application of the new representation\n",
    "        newdata = np.array([ex - self.u * (ex[self.max_i] / self.u[self.max_i]) for ex in self.dataset.data])\n",
    "        newdata = np.delete(newdata, self.max_i, 1)\n",
    "        self.dataset = namedtuple('_', 'data, target')(newdata, self.dataset.target)\n",
    "\n",
    "        # Fitting the linear model by using the new data\n",
    "        if self.model:\n",
    "            self.model.fit(self.dataset.data, self.dataset.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import copy\n",
    "\n",
    "\n",
    "train_dataset = namedtuple('_', 'data, target')(X_train.to_numpy(), y_train.to_numpy())\n",
    "test_dataset = namedtuple('_', 'data, target')(X_test.to_numpy(), y_test.to_numpy())\n",
    "\n",
    "# predictor must be trained (or otherwise have attribute 'estimators_'); predictor may be altered by the fit process (TODO: check this)\n",
    "lr_predictor = copy.deepcopy(lr_model)\n",
    "ermL_lr_model = Linear_FERM(train_dataset, lr_predictor, X_train['LANGUAGE_ENGL'].to_numpy())  \n",
    "ermL_lr_model.fit()\n",
    "y_pred_ermL_lr = ermL_lr_model.predict(test_dataset.data)\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_ermL_lr, target_names=['LOS <= mean', 'LOS > mean']) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# predictor must be trained (or otherwise have attribute 'estimators_'); predictor may be altered by the fit process (TODO: check this)\n",
    "svm_predictor = copy.deepcopy(svm_model)\n",
    "ermL_svm_model = Linear_FERM(train_dataset, svm_predictor, X_train['LANGUAGE_ENGL'].to_numpy())  \n",
    "ermL_svm_model.fit()\n",
    "y_pred_ermL_svm = ermL_svm_model.predict(test_dataset.data)\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_ermL_svm, target_names=['LOS <= mean', 'LOS > mean']) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Linear FERM\n",
    "\n",
    "Code taken from https://github.com/jmikko/fair_ERM/blob/master/ferm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import load_adult\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from measures import equalized_odds_measure_TP\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from cvxopt import matrix\n",
    "import numpy as np\n",
    "from numpy import linalg\n",
    "import cvxopt\n",
    "import cvxopt.solvers\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "\n",
    "# Definition of different kernels\n",
    "def linear_kernel(x1, x2):\n",
    "    return np.dot(x1, np.transpose(x2))\n",
    "\n",
    "def gaussian_kernel(x, y, gamma=0.1):\n",
    "    return np.exp(-gamma * (linalg.norm(x - y)**2))\n",
    "\n",
    "\n",
    "class FERM(BaseEstimator):\n",
    "    # FERM algorithm\n",
    "    def __init__(self, kernel='rbf', C=1.0, sensible_feature=None, gamma=1.0):\n",
    "        self.kernel = kernel\n",
    "        self.C = C\n",
    "        self.fairness = False if sensible_feature is None else True\n",
    "        self.sensible_feature = sensible_feature\n",
    "        self.gamma = gamma\n",
    "        self.w = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if self.kernel == 'rbf':\n",
    "            self.fkernel = lambda x, y: rbf_kernel(x, y, self.gamma)\n",
    "        elif self.kernel == 'linear':\n",
    "            self.fkernel = linear_kernel\n",
    "        else:\n",
    "            self.fkernel = linear_kernel\n",
    "\n",
    "        if self.fairness:\n",
    "            self.values_of_sensible_feature = list(set(self.sensible_feature))\n",
    "            self.list_of_sensible_feature_train = self.sensible_feature\n",
    "            self.val0 = np.min(self.values_of_sensible_feature)\n",
    "            self.val1 = np.max(self.values_of_sensible_feature)\n",
    "            self.set_A1 = [idx for idx, ex in enumerate(X) if y[idx] == 1\n",
    "                           and self.sensible_feature[idx] == self.val1]\n",
    "            self.set_not_A1 = [idx for idx, ex in enumerate(X) if y[idx] == 1\n",
    "                               and self.sensible_feature[idx] == self.val0]\n",
    "            # print('self.val0:', self.val0)\n",
    "            # print('self.val1:', self.val1)\n",
    "            # print('(y, self.sensible_feature):')\n",
    "            # for el in zip(y, self.sensible_feature):\n",
    "            #     print(el)\n",
    "            self.set_1 = [idx for idx, ex in enumerate(X) if y[idx] == 1]\n",
    "            self.n_A1 = len(self.set_A1)\n",
    "            self.n_not_A1 = len(self.set_not_A1)\n",
    "            self.n_1 = len(self.set_1)\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Gram matrix\n",
    "        K = self.fkernel(X, X)\n",
    "\n",
    "        P = cvxopt.matrix(np.outer(y, y) * K)\n",
    "        q = cvxopt.matrix(np.ones(n_samples) * -1)\n",
    "        # print(y)\n",
    "        A = cvxopt.matrix(y.astype(np.double), (1, n_samples), 'd')\n",
    "        b = cvxopt.matrix(0.0)\n",
    "\n",
    "        if self.C is None:\n",
    "            G = cvxopt.matrix(np.diag(np.ones(n_samples) * -1))\n",
    "            h = cvxopt.matrix(np.zeros(n_samples))\n",
    "        else:\n",
    "            tmp1 = np.diag(np.ones(n_samples) * -1)\n",
    "            tmp2 = np.identity(n_samples)\n",
    "            G = cvxopt.matrix(np.vstack((tmp1, tmp2)))\n",
    "            tmp1 = np.zeros(n_samples)\n",
    "            tmp2 = np.ones(n_samples) * self.C\n",
    "            h = cvxopt.matrix(np.hstack((tmp1, tmp2)))\n",
    "\n",
    "        # Stack the fairness constraint\n",
    "        if self.fairness:\n",
    "            tau = [(np.sum(K[self.set_A1, idx]) / self.n_A1) - (np.sum(K[self.set_not_A1, idx]) / self.n_not_A1)\n",
    "                   for idx in range(len(y))]\n",
    "            # print('self.n_A1:', self.n_A1)\n",
    "            # print('self.n_not_A1:', self.n_not_A1)\n",
    "            # print('tau:', tau)\n",
    "            fairness_line = matrix(y * tau, (1, n_samples), 'd')\n",
    "            A = cvxopt.matrix(np.vstack([A, fairness_line]))\n",
    "            b = cvxopt.matrix([0.0, 0.0])\n",
    "\n",
    "        # solve QP problem\n",
    "        cvxopt.solvers.options['show_progress'] = False\n",
    "        # print('A:', A)\n",
    "        # print('Rank(A):', np.linalg.matrix_rank(A))\n",
    "        # print('Rank([P; A; G])', np.linalg.matrix_rank(np.vstack([P, A, G])))\n",
    "        solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "\n",
    "        # Lagrange multipliers\n",
    "        a = np.ravel(solution['x'])\n",
    "\n",
    "        # Support vectors have non zero lagrange multipliers\n",
    "        sv = a > 1e-7\n",
    "        ind = np.arange(len(a))[sv]\n",
    "        self.a = a[sv]\n",
    "        self.sv = X[sv]\n",
    "        self.sv_y = y[sv]\n",
    "        # print(\"%d support vectors out of %d points\" % (len(self.a), n_samples))\n",
    "\n",
    "        # Intercept\n",
    "        self.b = 0\n",
    "        for n in range(len(self.a)):\n",
    "            self.b += self.sv_y[n]\n",
    "            self.b -= np.sum(self.a * self.sv_y * K[ind[n], sv])\n",
    "        self.b /= len(self.a)\n",
    "\n",
    "        # Weight vector\n",
    "        if self.kernel == linear_kernel:\n",
    "            self.w = np.zeros(n_features)\n",
    "            for n in range(len(self.a)):\n",
    "                self.w += self.a[n] * self.sv_y[n] * self.sv[n]\n",
    "        else:\n",
    "            self.w = None\n",
    "\n",
    "    def project(self, X):\n",
    "        if self.w is not None:\n",
    "            return np.dot(X, self.w) + self.b\n",
    "        else:\n",
    "            XSV = self.fkernel(X, self.sv)\n",
    "            a_sv_y = np.multiply(self.a, self.sv_y)\n",
    "            y_predict = [np.sum(np.multiply(np.multiply(self.a, self.sv_y), XSV[i, :])) for i in range(len(X))]\n",
    "\n",
    "            return y_predict + self.b\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        return self.project(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(self.project(X))\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        predict = self.predict(X_test)\n",
    "        acc = accuracy_score(y_test, predict)\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'C': [0.1, 1, 10.0], 'gamma': [0.1, 0.01], 'kernel': ['rbf']} ]\n",
    "\n",
    "# predictor must be trained (or otherwise have attribute 'estimators_'); predictor may be altered by the fit process (TODO: check this)\n",
    "svm_predictor = copy.deepcopy(svm_model)\n",
    "\n",
    "algorithm = FERM(sensible_feature=train_dataset.data[:, sensible_feature])\n",
    "clf = GridSearchCV(algorithm, param_grid, n_jobs=1)\n",
    "clf.fit(dataset_train.data, dataset_train.target)\n",
    "print('Best Fair Estimator:', clf.best_estimator_)\n",
    "\n",
    "# Accuracy and Fairness\n",
    "y_predict = clf.predict(dataset_test.data)\n",
    "pred = clf.predict(dataset_test.data)\n",
    "pred_train = clf.predict(dataset_train.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Part 3 - Comparing Models <a class=\"anchor\" id=\"part3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we'll generate a set of dictionaries that will allow us to view our models in meaningful groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_models = {'naive_bayes_model':nb_model, 'decision_tree_model':dt_model}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ermL_lr_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-404cc7a73a30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcommon_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'naive_bayes_model'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'decision_tree_model'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdt_model\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlinear_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'lr_model'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlr_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ermL_lr_model'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mermL_lr_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'svm_model'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msvm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ermL_svm_model'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mermL_svm_model\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mboosted_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'xgboost_model'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gs_xgb_model'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mgs_xgb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lgbm_model'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlgb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gs_lgbm_model'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mgs_lgb_model\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#rf_models ={'rf_model':rf_model, 'gs_rfEO_model':gs_rfEO_model, 'gs_rfDP_model':gs_rfDP_model, 'eg_rf_model':eg_rf_model, 'ermL_rf_model':ermL_rf_model}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ermL_lr_model' is not defined"
     ]
    }
   ],
   "source": [
    "#\n",
    "common_models = {'naive_bayes_model':nb_model, 'decision_tree_model':dt_model}\n",
    "linear_models = {'lr_model':lr_model, 'ermL_lr_model':ermL_lr_model, 'svm_model':svm_model, 'ermL_svm_model':ermL_svm_model}\n",
    "boosted_models = {'xgboost_model':xgb_model, 'gs_xgb_model':gs_xgb_model, 'lgbm_model':lgb_model, 'gs_lgbm_model':gs_lgb_model}\n",
    "#rf_models ={'rf_model':rf_model, 'gs_rfEO_model':gs_rfEO_model, 'gs_rfDP_model':gs_rfDP_model, 'eg_rf_model':eg_rf_model, 'ermL_rf_model':ermL_rf_model}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with the FairMLHealth Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_comp = fhmc.compare_models(X_test, y_test, X_test['LANGUAGE_ENGL'], common_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_comp = fhmc.compare_models(X_test, y_test, X_test['LANGUAGE_ENGL'], linear_models)\n",
    "\n",
    "fhmc.flag_suspicous(lin_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aif_dataset_measures(dataset=los_dataset, \n",
    "                       models={'aif_gf_model':aif_gf_model, 'aif_prr_model':aif_prr_model}) #, 'aif_adb_model':aif_adb_model })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhmc.compare_models(X_test, y_test, X_test['LANGUAGE_ENGL'], boosted_models) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhmc.compare_models(X_test, y_test, X_test['LANGUAGE_ENGL'], rf_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with the FairLearn Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) View this model in Fairlearn's fairness dashboard, and see the disparities which appear:\n",
    "from fairlearn.widget import FairlearnDashboard\n",
    "FairlearnDashboard(sensitive_features=X_test['LANGUAGE_ENGL'].to_list(), \n",
    "                   sensitive_feature_names=['LANGUAGE_ENGL'],\n",
    "                   y_true=y_test.iloc[:,0].to_list(),\n",
    "                   y_pred={k:model.predict(X_test) for k,model in common_models.items()}\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Part 4 - Save Results <a class=\"anchor\" id=\"part4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_models = rf_models\n",
    "\n",
    "packet = fhmc.fairCompare(test_data=X_test, target_data=y_test, models=models, train_data=train_data)\n",
    "if not os.path.exists(os.path.dirname(output_file)):\n",
    "        os.makedirs(output_file)\n",
    "#dump(packet, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
